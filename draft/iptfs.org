# -*- fill-column: 69; org-confirm-babel-evaluate: nil -*-
#+STARTUP: align entitiespretty hidestars inlineimages latexpreview noindent showall
#
#+TITLE: IP Traffic Flow Security Using Aggregation and Fragmentation
#+AUTHOR: Christian Hopps
#+EMAIL: chopps@chopps.org
#+AFFILIATION: LabN Consulting, L.L.C.
#
#+RFC_NAME: draft-ietf-ipsecme-iptfs
#+RFC_SHORT_TITLE: IP Traffic Flow Security
#+RFC_VERSION: 05
#+RFC_XML_VERSION: 2
#+RFC_ASCII_TABLE: t
#
# Do: title, table-of-contents ::fixed-width-sections |tables
# Do: ^:sup/sub with curly -:special-strings *:emphasis
# Don't: prop:no-prop-drawers \n:preserve-linebreaks ':use-smart-quotes
#+OPTIONS: prop:nil title:t toc:t \n:nil ::t |:t ^:{} -:t *:t ':nil


#+begin_abstract
This document describes a mechanism to enhance IPsec traffic flow
security by adding traffic flow confidentiality to encrypted IP
encapsulated traffic. Traffic flow confidentiality is provided by
obscuring the size and frequency of IP traffic using a fixed-sized,
constant-send-rate IPsec tunnel. The solution allows for congestion
control as well as non-constant send-rate usage.
#+end_abstract

* Introduction

Traffic Analysis ([[RFC4301]], [[AppCrypt]]) is the act of extracting
information about data being sent through a network. While one may
directly obscure the data through the use of encryption [[RFC4303]],
the traffic pattern itself exposes information due to variations in
it's shape and timing ([[I-D.iab-wire-image]], [[AppCrypt]]).
Hiding the size and frequency of traffic is referred to as Traffic
Flow Confidentiality (TFC) per [[RFC4303]].

[[RFC4303]] provides for TFC by allowing padding to be added to encrypted
IP packets and allowing for transmission of all-pad packets
(indicated using protocol 59). This method has the major limitation
that it can significantly under-utilize the available bandwidth.

The IP-TFS solution provides for full TFC without the aforementioned
bandwidth limitation. This is accomplished by using a
constant-send-rate IPsec [[RFC4303]] tunnel with fixed-sized
encapsulating packets; however, these fixed-sized packets can contain
partial, whole or multiple IP packets to maximize the bandwidth of
the tunnel. A non-constant send-rate is allowed, but the
confidentiality properties of its use are outside the scope of this
document.

For a comparison of the overhead of IP-TFS with the RFC4303
prescribed TFC solution see [[Comparisons of IP-TFS]].

Additionally, IP-TFS provides for dealing with network congestion
[[RFC2914]]. This is important for when the IP-TFS user is not in full
control of the domain through which the IP-TFS tunnel path flows.

** Terminology & Concepts

The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
"SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in
[[RFC2119]] [[RFC8174]] when, and only when, they appear in all capitals,
as shown here.

This document assumes familiarity with IP security concepts described
in [[RFC4301]].

* The IP-TFS Tunnel

As mentioned in [[Introduction]] IP-TFS utilizes an IPsec [[RFC4303]] tunnel
(SA) as it's transport. To provide for full TFC, fixed-sized
encapsulating packets are sent at a constant rate on the tunnel.

The primary input to the tunnel algorithm is the requested bandwidth
used by the tunnel. Two values are then required to provide for this
bandwidth, the fixed size of the encapsulating packets, and rate at
which to send them.

The fixed packet size MAY either be specified manually or could be
determined through the other methods such as the Packetization Layer
MTU Discovery (PLMTUD) ([[RFC4821]], [[RFC8899]]) or Path MTU discovery
(PMTUD) ([[RFC1191]], [[RFC8201)]]. PMTUD is known to have issues so PLMTUD
is considered the more robust option.

Given the encapsulating packet size and the requested tunnel used
bandwidth, the corresponding packet send rate can be calculated. The
packet send rate is the requested bandwidth divided by the size of
the encapsulating packet.

The egress of the IP-TFS tunnel MUST allow for and expect the ingress
(sending) side of the IP-TFS tunnel to vary the size and rate of
sent encapsulating packets, unless constrained by other policy.

** Tunnel Content

As previously mentioned, one issue with the TFC padding solution in
[[RFC4303]] is the large amount of wasted bandwidth as only one IP
packet can be sent per encapsulating packet. In order to maximize
bandwidth IP-TFS breaks this one-to-one association.

IP-TFS aggregates as well as fragments the inner IP traffic flow into
fixed-sized encapsulating IPsec tunnel packets. Padding is only added
to the the tunnel packets if there is no data available to be sent at
the time of tunnel packet transmission, or if fragmentation has been
disabled by the receiver.

This is accomplished using a new Encapsulating Security Payload (ESP,
[[RFC4303]]) type which is identified by the number AGGFRAG_PAYLOAD
([[AGGFRAG_PAYLOAD Payload]]).

Other non-IP-TFS uses of this aggregation and fragmentation
encapsulation have been identified, such as increased performance
through packet aggregation, as well as handling MTU issues using
fragmentation. These uses are not defined here, but are also not
restricted by this document.

** Payload Content

The AGGFRAG_PAYLOAD payload content defined in this document is
comprised of a 4 or 24 octet header followed by either a partial, a
full or multiple partial or full data blocks. The following diagram
illustrates this payload within the ESP packet. See [[AGGFRAG_PAYLOAD
Payload]] for the exact formats of the AGGFRAG_PAYLOAD payload.

#+CAPTION: Layout of an IP-TFS IPsec Packet
#+begin_example
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . Outer Encapsulating Header ...                                .
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . ESP Header...                                                 .
 +---------------------------------------------------------------+
 |   [AGGFRAG subtype/flags]    :           BlockOffset          |
 +---------------------------------------------------------------+
 :                  [Optional Congestion Info]                   :
 +---------------------------------------------------------------+
 |       DataBlocks ...                                          ~
 ~                                                               ~
 ~                                                               |
 +---------------------------------------------------------------|
 . ESP Trailer...                                                .
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
#+end_example

The ~BlockOffset~ value is either zero or some offset into or past
the end of the ~DataBlocks~ data.

If the ~BlockOffset~ value is zero it means that the ~DataBlocks~
data begins with a new data block.

Conversely, if the ~BlockOffset~ value is non-zero it points to the
start of the new data block, and the initial ~DataBlocks~ data
belongs to a previous data block that is still being re-assembled.

The ~BlockOffset~ can point past the end of the ~DataBlocks~ data
which indicates that the next data block occurs in a subsequent
encapsulating packet.

Having the ~BlockOffset~ always point at the next available data
block allows for recovering the next inner packet in the
presence of outer encapsulating packet loss.

An example IP-TFS packet flow can be found in [[Example Of An
Encapsulated IP Packet Flow]].

*** Data Blocks

#+CAPTION: Layout of IP-TFS data block
#+begin_example
 +---------------------------------------------------------------+
 | Type  | rest of IPv4, IPv6 or pad.
 +--------
#+end_example

A data block is defined by a 4-bit type code followed by the data
block data. The type values have been carefully chosen to coincide
with the IPv4/IPv6 version field values so that no per-data block
type overhead is required to encapsulate an IP packet. Likewise, the
length of the data block is extracted from the encapsulated IPv4 or
IPv6 packet's length field.

*** No Implicit End Padding Required

It's worth noting that since a data block type is identified by its
first octet there is never a need for an implicit pad at the end of
an encapsulating packet. Even when the start of a data block occurs
near the end of a encapsulating packet such that there is no room for
the length field of the encapsulated header to be included in the
current encapsulating packet, the fact that the length comes at a
known location and is guaranteed to be present is enough to fetch the
length field from the subsequent encapsulating packet payload. Only
when there is no data to encapsulated is end padding required, and
then an explicit ~Pad Data Block~ would be used to identify the
padding.

*** Fragmentation, Sequence Numbers and All-Pad Payloads

In order for a receiver to be able to reassemble fragmented
inner-packets, the sender MUST send the inner-packet fragments
back-to-back in the logical outer packet stream (i.e., using
consecutive ESP sequence numbers). However, the sender is allowed to
insert "all-pad" payloads (i.e., payloads with a ~BlockOffset~ of
zero and a single pad ~DataBlock~) in between the packets carrying
the inner-packet fragment payloads. This possible interleaving of
all-pad payloads allows the sender to always be able to send a tunnel
packet, regardless of the encapsulation computational requirements.

When a receiver is reassembling an inner-packet, and it receives an
"all-pad" payload, it increments the expected sequence number that
the next inner-packet fragment is expected to arrive in.

Given the above, the receiver will need to handle out-of-order
arrival of outer ESP packets prior to reassembly processing. ESP
already provides for detecting replay attacks (normally) utilizing a
window. A similar sequence number based sliding window can be used to
correct re-ordering of the outer packet stream. Receiving a larger
(newer) sequence number packet advances the window, and received
older ESP packets whose sequence numbers the window has passed by are
dropped. A good choice for the size of this window depends on the
amount of re-ordering the user may normally experience. As the amount
of reordering that may be present is hard to predict the window size
SHOULD be configurable by the user. Implementations MAY also
dynamically adjust the reordering window based on actual reordering
seen in arriving packets. Finally, we note that as IP-TFS is sending
a continuous stream of packets there is no requirement for timers
(although there's no prohibition either) as newly arrived packets
will cause the window to advance and older packets will then be
processed as they leave the window.

**** Optional Extra Padding

When the tunnel bandwidth is not being fully utilized, an
implementation MAY pad-out the current encapsulating packet in order
to deliver an inner packet un-fragmented in the following outer
packet. The benefit would be to avoid inner-packet fragmentation in
the presence of a bursty offered load (non-bursty traffic will
naturally not fragment). The cost is complexity and added delay of
inner traffic. The main advantage to avoiding fragmentation is to
minimize inner packet loss in the presence of outer packet loss. When
this is worthwhile (e.g., how much loss and what type of loss is
required, given different inner traffic shapes and utilization, for
this to make sense), and what values to use for the allowable/added
delay may be worth researching, but is outside the scope of this
document.

While clever use of padding to avoid fragmentation does not impact
interoperability, used inappropriately it can reduce the effective
throughput of a tunnel. Implementations experimenting with the above
approach will need to take care to not reduce the effective capacity,
and overall utility, of the tunnel through the overuse of padding.

*** Empty Payload

In order to support reporting of congestion control information
(described later) on a non-AGGFRAG_PAYLOAD enabled SA, IP-TFS allows
for the sending of an AGGFRAG_PAYLOAD payload with no data blocks
(i.e., the ESP payload length is equal to the AGGFRAG_PAYLOAD header
length). This special payload is called an empty payload.

*** IP Header Value Mapping

[[RFC4301]] provides some direction on when and how to map various values
from an inner IP header to the outer encapsulating header, namely the
Don't-Fragment (DF) bit ([[RFC0791]] and [[RFC8200]]), the Differentiated
Services (DS) field [[RFC2474]] and the Explicit Congestion Notification
(ECN) field [[RFC3168]]. Unlike [[RFC4301]], IP-TFS may and often will be
encapsulating more than one IP packet per ESP packet. To deal with
this, these mappings are restricted further. In particular
IP-TFS never maps the inner DF bit as it is unrelated to the IP-TFS
tunnel functionality; IP-TFS never IP fragments the inner packets and
the inner packets will not affect the fragmentation of the outer
encapsulation packets. Likewise, the ECN value need not be mapped as
any congestion related to the constant-send-rate IP-TFS tunnel is
unrelated (by design!) to the inner traffic flow. Finally, by default
the DS field SHOULD NOT be copied although an implementation MAY
choose to allow for configuration to override this behavior. An
implementation SHOULD also allow the DS value to be set by
configuration.

** Exclusive SA Use

It is not the intention of this specification to allow for mixed use
of an AGGFRAG_PAYLOAD enabled SA. In other words, an SA that has
AGGFRAG_PAYLOAD enabled MUST NOT have non-AGGFRAG_PAYLOAD payloads
such as IP (IP protocol 4), TCP transport (IP protocol 6), or ESP pad
packets (protocol 59) intermixed with non-empty AGGFRAG_PAYLOAD
payloads. While it's possible to envision making the algorithm work
in the presence of sequence number skips in the AGGFRAG_PAYLOAD
payload stream, the added complexity is not deemed worthwhile. Other
IPsec uses can configure and use their own SAs.

** Modes of Operation

Just as with normal IPsec/ESP tunnels, IP-TFS tunnels are
unidirectional. Bidirectional IP-TFS functionality is achieved by
setting up 2 IP-TFS tunnels, one in either direction.

An IP-TFS tunnel can operate in 2 modes, a non-congestion controlled
mode and congestion controlled mode.

*** Non-Congestion Controlled Mode

In the non-congestion controlled mode IP-TFS sends fixed-sized
packets at a constant rate. The packet send rate is constant and is
not automatically adjusted regardless of any network congestion
(e.g., packet loss).

For similar reasons as given in [[RFC7510]] the non-congestion
controlled mode should only be used where the user has full
administrative control over the path the tunnel will take. This is
required so the user can guarantee the bandwidth and also be sure as
to not be negatively affecting network congestion [[RFC2914]]. In this
case packet loss should be reported to the administrator (e.g.,
via syslog, YANG notification, SNMP traps, etc) so that any
failures due to a lack of bandwidth can be corrected.

*** Congestion Controlled Mode

With the congestion controlled mode, IP-TFS adapts to network
congestion by lowering the packet send rate to accommodate the
congestion, as well as raising the rate when congestion subsides.
Since overhead is per packet, by allowing for maximal fixed-size
packets and varying the send rate transport overhead is minimized.

The output of the congestion control algorithm will adjust the rate
at which the ingress sends packets. While this document does not
require a specific congestion control algorithm, best current
practice RECOMMENDS that the algorithm conform to [[RFC5348]]. Congestion
control principles are documented in [[RFC2914]] as well. An example of
an implementation of the [[RFC5348]] algorithm which matches the
requirements of IP-TFS (i.e., designed for fixed-size packet and send
rate varied based on congestion) is documented in [[RFC4342]].

The required inputs for the TCP friendly rate control algorithm
described in [[RFC5348]] are the receiver's loss event rate and the
sender's estimated round-trip time (RTT). These values are provided by
IP-TFS using the congestion information header fields described in
[[Congestion Information]]. In particular these values are sufficient to
implement the algorithm described in [[RFC5348]].

At a minimum, the congestion information must be sent, from the
receiver and from the sender, at least once per RTT. Prior to
establishing an RTT the information SHOULD be sent constantly from
the sender and the receiver so that an RTT estimate can be
established. The lack of receiving this information over multiple
consecutive RTT intervals should be considered a congestion event
that causes the sender to adjust it's sending rate lower. For
example, [[RFC4342]] calls this the "no feedback timeout" and it is equal
to 4 RTT intervals. When a "no feedback timeout" has occurred [[RFC4342]]
halves the sending rate.

An implementation MAY choose to always include the congestion
information in it's IP-TFS payload header if sending on an IP-TFS
enabled SA. Since IP-TFS normally will operate with a large packet
size, the congestion information should represent a small portion of
the available tunnel bandwidth. An implementation choosing to always
send the data MAY also choose to only update the ~LossEventRate~
and ~RTT~ header field values it sends every ~RTT~ though.

# XXX [[Deriving TFRC Parameters]] describes how the data provided by
# IP-TFS congestion information may be used to derive the values
# required in [[RFC5348]].

When an implementation is choosing a congestion control algorithm (or
a selection of algorithms) one should remember that IP-TFS is not
providing for reliable delivery of IP traffic, and so per packet ACKs
are not required and are not provided.

It's worth noting that the variable send-rate of a congestion
controlled IP-TFS tunnel, is not private; however, this send-rate is
being driven by network congestion, and as long as the encapsulated
(inner) traffic flow shape and timing are not directly affecting the
(outer) network congestion, the variations in the tunnel rate will
not weaken the provided inner traffic flow confidentiality.

**** Circuit Breakers

In additional to congestion control, implementations MAY choose to
define and implement circuit breakers [[RFC8084]] as a recovery method
of last resort. Enabling circuit breakers is also a reason a user may
wish to enable congestion information reports even when using the
non-congestion controlled mode of operation. The definition of
circuit breakers are outside the scope of this document.

* Congestion Information

In order to support the congestion control mode, the sender needs to
know the loss event rate and also be able to approximate the RTT
([[RFC5348]]). In order to obtain these values the receiver sends
congestion control information on it's SA back to the sender. Thus,
in order to support congestion control the receiver must have a
paired SA back to the sender (this is always the case when the tunnel
was created using IKEv2). If the SA back to the sender is a
non-AGGFRAG_PAYLOAD enabled SA then an AGGFRAG_PAYLOAD empty payload
(i.e., header only) is used to convey the information.

In order to calculate a loss event rate compatible with [[RFC5348]], the
receiver needs to have a round-trip time estimate. Thus the sender
communicates this estimate in the ~RTT~ header field. On startup this
value will be zero as no RTT estimate is yet known.

In order for the sender to estimate it's ~RTT~ value, the sender
places a timestamp value in the ~TVal~ header field. On first receipt
of this ~TVal~, the receiver records the new ~TVal~ value along with
the time it arrived locally, subsequent receipt of the same ~TVal~
MUST not update the recorded time. When the receiver sends it's CC
header it places this latest recorded value in the ~TEcho~ header
field, along with 2 delay values, ~Echo Delay~ and ~Transmit Delay~.
The ~Echo Delay~ value is the time delta from the recorded arrival
time of ~TVal~ and the current clock in microseconds. The second
value, ~Transmit Delay~, is the receiver's current transmission delay
on the tunnel (i.e., the average time between sending packets on it's
half of the IP-TFS tunnel). When the sender receives back it's ~TVal~
in the ~TEcho~ header field it calculates 2 RTT estimates. The first
is the actual delay found by subtracting the ~TEcho~ value from it's
current clock and then subtracting ~Echo Delay~ as well. The second
RTT estimate is found by adding the received ~Transmit Delay~ header
value to the senders own transmission delay (i.e., the average time
between sending packets on it's half of the IP-TFS tunnel). The
larger of these 2 RTT estimates SHOULD be used as the ~RTT~ value.
The two estimates are required to handle different combinations of
faster or slower tunnel packet paths with faster or slower fixed
tunnel rates. Choosing the larger of the two values guarantees that
the ~RTT~ is never considered faster than the aggregate transmission
delay based on the IP-TFS tunnel rate (the second estimate), as well
as never being considered faster than the actual RTT along the tunnel
packet path (the first estimate).

The receiver also calculates, and communicates in the ~LossEventRate~
header field, the loss event rate for use by the sender. This is
slightly different from [[RFC4342]] which periodically sends all the loss
interval data back to the sender so that it can do the calculation.
See [[A Send and Loss Event Rate Calculation]] for a suggested way to
calculate the loss event rate value. Initially this value will be
zero (indicating no loss) until enough data has been collected by the
receiver to update it.

** ECN Support

In additional to normal packet loss information IP-TFS supports use
of the ECN bits in the encapsulating IP header [[RFC3168]] for
identifying congestion. If ECN use is enabled and a packet arrives at
the egress endpoint with the Congestion Experienced (CE) value set,
then the receiver considers that packet as being dropped, although it
does not drop it. The receiver MUST set the E bit in any
AGGFRAG_PAYLOAD payload header containing a ~LossEventRate~ value
derived from a CE value being considered.

# XXX replace with immediately consider the loss interval done? XXX
# In order to respond quickly to the
# congestion indication the receiver MAY immediately send a congestion
# information notification to the sender upon receiving a packet with
# the CE indication. This additional immediate send SHOULD only be done
# once per normal congestion information sending interval though.

As noted in [[RFC3168]] the ECN bits are not protected by IPsec and
thus may constitute a covert channel. For this reason ECN use SHOULD
NOT be enabled by default.

* Configuration

IP-TFS is meant to be deployable with a minimal amount of
configuration. All IP-TFS specific configuration should be able to be
specified at the unidirectional tunnel ingress (sending) side. It
is intended that non-IKEv2 operation is supported, at least, with
local static configuration.

** Bandwidth

Bandwidth is a local configuration option. For non-congestion
controlled mode the bandwidth SHOULD be configured. For
congestion controlled mode one can configure the bandwidth
or have no configuration and let congestion control discover the
maximum bandwidth available. No standardized configuration method is
required.

** Fixed Packet Size

The fixed packet size to be used for the tunnel encapsulation packets
MAY be configured manually or can be automatically determined using
other methods such as PLMTUD ([[RFC4821]], [[RFC8899]]) or PMTUD ([[RFC1191]],
[[RFC8201]]). As PMTUD is known to have issues, PLMTUD is considered the
more robust option. No standardized configuration method is required.

** Congestion Control

Congestion control is a local configuration option. No standardized
configuration method is required.

* IKEv2

** USE_AGGFRAG Notification Message

As mentioned previously IP-TFS tunnels utilize ESP payloads of type
AGGFRAG_PAYLOAD.

When using IKEv2, a new "USE_AGGFRAG" Notification Message is used to
enable use of the AGGFRAG_PAYLOAD payload on a child SA pair. The
method used is similar to how USE_TRANSPORT_MODE is negotiated, as
described in [[RFC7296]].

To request using the AGGFRAG_PAYLOAD payload on the Child SA pair,
the initiator includes the USE_AGGFRAG notification in an SA payload
requesting a new Child SA (either during the initial IKE_AUTH or
during non-rekeying CREATE_CHILD_SA exchanges). If the request is
accepted then response MUST also include a notification of type
USE_AGGFRAG. If the responder declines the request the child SA will
be established without AGGFRAG_PAYLOAD payload use enabled. If
this is unacceptable to the initiator, the initiator MUST delete the
child SA.

The USE_AGGFRAG notification MUST NOT be sent, and MUST be ignored,
during a CREATE_CHILD_SA rekeying exchange as it is not allowed to
change use of the AGGFRAG_PAYLOAD payload type during rekeying.

The USE_AGGFRAG notification contains a 1 octet payload of flags that
specify any requirements from the sender of the message. If any
requirement flags are not understood or cannot be supported by the
receiver then the receiver should not enable use of AGGFRAG_PAYLOAD
payload type (either by not responding with the USE_AGGFRAG
notification, or in the case of the initiator, by deleting the child
SA if the now established non-AGGFRAG_PAYLOAD using SA is
unacceptable).

The notification type and payload flag values are defined in [[IKEv2
USE_AGGFRAG Notification Message]].

* Packet and Data Formats

** AGGFRAG_PAYLOAD Payload

   ESP Payload Type: 0x5

An IP-TFS payload is identified by the ESP payload type AGGFRAG_PAYLOAD
which has the value 0x5. The first octet of this payload indicates the
format of the remaining payload data.

#+begin_example
  0 1 2 3 4 5 6 7
 +-+-+-+-+-+-+-+-+-+-+-
 |   Sub-type    | ...
 +-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Sub-type :: An 8 bit value indicating the payload format.

This specification defines 2 payload sub-types. These payload formats
are defined in the following sections.

*** Non-Congestion Control AGGFRAG_PAYLOAD Payload Format

The non-congestion control AGGFRAG_PAYLOAD payload is comprised of a 4
octet header followed by a variable amount of ~DataBlocks~ data as
shown below.

#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  Sub-Type (0) |   Reserved    |          BlockOffset          |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |       DataBlocks ...
 +-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Sub-type :: An octet indicating the payload format. For this
              non-congestion control format, the value is 0.
- Reserved :: An octet set to 0 on generation, and ignored on
              receipt.
- BlockOffset :: A 16 bit unsigned integer counting the number of
                 octets of ~DataBlocks~ data before the start of a
                 new data block. ~BlockOffset~ can count past the end
                 of the ~DataBlocks~ data in which case all the
                 ~DataBlocks~ data belongs to the previous data block
                 being re-assembled. If the ~BlockOffset~ extends
                 into subsequent packets it continues to only count
                 subsequent ~DataBlocks~ data (i.e., it does not
                 count subsequent packets non-~DataBlocks~ octets).
- DataBlocks :: Variable number of octets that begins with the start
                of a data block, or the continuation of a previous
                data block, followed by zero or more additional data
                blocks.

*** Congestion Control AGGFRAG_PAYLOAD Payload Format

The congestion control AGGFRAG_PAYLOAD payload is comprised of a 24
octet header followed by a variable amount of ~DataBlocks~ data as
shown below.

#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  Sub-type (1) |  Reserved   |E|          BlockOffset          |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                          LossEventRate                        |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                      RTT                  |   Echo Delay ...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      ... Echo Delay   |           Transmit Delay                |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                              TVal                             |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                             TEcho                             |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |       DataBlocks ...
 +-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Sub-type :: An octet indicating the payload format. For this
              congestion control format, the value is 1.
- Reserved :: A 7 bit field set to 0 on generation, and ignored on
              receipt.
- E :: A 1 bit value if set indicates that Congestion Experienced
       (CE) ECN bits were received and used in deriving the
       reported ~LossEventRate~.
- BlockOffset :: The same value as the non-congestion controlled
                 payload format value.
- LossEventRate :: A 32 bit value specifying the inverse of the
                   current loss event rate as calculated by the
                   receiver. A value of zero indicates no loss.
                   Otherwise the loss event rate is
                   ~1/LossEventRate~.
- RTT :: A 22 bit value specifying the sender's current round-trip
         time estimate in microseconds. The value MAY be zero prior
         to the sender having calculated a round-trip time estimate.
         The value SHOULD be set to zero on non-AGGFRAG_PAYLOAD
         enabled SAs. If the value is equal to or larger than
         ~0x3FFFFF~ it MUST be set to ~0x3FFFFF~.
- Echo Delay :: A 21 bit value specifying the delay in microseconds
           incurred between the receiver first receiving the ~TVal~
           value which it is sending back in ~TEcho~. If the value
           is equal to or larger than ~0x1FFFFF~ it MUST be set to
           ~0x1FFFFF~.
- Transmit Delay :: A 21 bit value specifying the transmission delay in
           microseconds. This is the fixed (or average) delay on the
           receiver between it sending packets on the IPTFS tunnel.
           If the value is equal to or larger than ~0x1FFFFF~ it MUST
           be set to ~0x1FFFFF~.
- TVal :: An opaque 32 bit value that will be echoed back by the
          receiver in later packets in the ~TEcho~ field, along with
          an ~Echo Delay~ value of how long that echo took.
- TEcho :: The opaque 32 bit value from a received packet's ~TVal~
           field. The received ~TVal~ is placed in ~TEcho~ along with
           an ~Echo Delay~ value indicating how long it has been since
           receiving the ~TVal~ value.
- DataBlocks :: Variable number of octets that begins with the start
                of a data block, or the continuation of a previous
                data block, followed by zero or more additional data
                blocks. For the special case of sending congestion
                control information on an non-IP-TFS enabled SA this
                value MUST be empty (i.e., be zero octets long).

*** Data Blocks
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 | Type  | IPv4, IPv6 or pad...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Type :: A 4 bit field where 0x0 identifies a pad data block, 0x4
          indicates an IPv4 data block, and 0x6 indicates an IPv6
          data block.

**** IPv4 Data Block
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  0x4  |  IHL  |  TypeOfService  |         TotalLength         |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 | Rest of the inner packet ...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#+end_example

These values are the actual values within the encapsulated IPv4
header. In other words, the start of this data block is the start of
the encapsulated IP packet.

- Type :: A 4 bit value of 0x4 indicating IPv4 (i.e., first nibble of
          the IPv4 packet).
- TotalLength :: The 16 bit unsigned integer "Total Length" field of
                 the IPv4 inner packet.

**** IPv6 Data Block
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  0x6  | TrafficClass  |               FlowLabel               |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |         PayloadLength         | Rest of the inner packet ...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#+end_example

These values are the actual values within the encapsulated IPv6
header. In other words, the start of this data block is the start of
the encapsulated IP packet.

- Type :: A 4 bit value of 0x6 indicating IPv6 (i.e., first nibble of
          the IPv6 packet).
- PayloadLength :: The 16 bit unsigned integer "Payload Length" field
                   of the inner IPv6 inner packet.

**** Pad Data Block
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  0x0  | Padding ...
 +-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Type :: A 4 bit value of 0x0 indicating a padding data block.
- Padding :: extends to end of the encapsulating packet.

*** IKEv2 USE_AGGFRAG Notification Message

As discussed in [[USE_AGGFRAG Notification Message]] a notification
message USE_AGGFRAG is used to negotiate use of the ESP AGGFRAG_PAYLOAD
payload type.

The USE_AGGFRAG Notification Message State Type is (TBD2).

The notification payload contains 1 octet of requirement flags. There
are currently 2 requirement flags defined. This may be revised by
later specifications.

#+begin_example
 +-+-+-+-+-+-+-+-+
 |0|0|0|0|0|0|C|D|
 +-+-+-+-+-+-+-+-+
#+end_example

- 0 :: 6 bits - reserved, MUST be zero on send, unless defined by
  later specifications.
- C :: Congestion Control bit. If set, then the sender is requiring
  that congestion control information MUST be returned to it
  periodically as defined in [[Congestion Information]].
- D :: Don't Fragment bit, if set indicates the sender of the notify
  message does not support receiving packet fragments (i.e., inner
  packets MUST be sent using a single ~Data Block~). This value only
  applies to what the sender is capable of receiving; the sender MAY
  still send packet fragments unless similarly restricted by the
  receiver in it's USE_AGGFRAG notification.

* IANA Considerations

** AGGFRAG_PAYLOAD Sub-Type Registry

This document requests IANA create a registry called "AGGFRAG_PAYLOAD
Sub-Type Registry" under a new category named "ESP AGGFRAG_PAYLOAD Parameters".
The registration policy for this registry is "Standards Action"
([[RFC8126]] and [[RFC7120]]).

  - Name :: AGGFRAG_PAYLOAD Sub-Type Registry
  - Description :: AGGFRAG_PAYLOAD Payload Formats.
  - Reference :: This document

This initial content for this registry is as follows:

| Sub-Type | Name                          | Reference     |
|----------+-------------------------------+---------------|
|        0 | Non-Congestion Control Format | This document |
|        1 | Congestion Control Format     | This document |
|    3-255 | Reserved                      |               |

** USE_AGGFRAG Notify Message Status Type

This document requests a status type USE_AGGFRAG be allocated from
the "IKEv2 Notify Message Types - Status Types" registry.

  - Value :: TBD2
  - Name :: USE_AGGFRAG
  - Reference :: This document

# ^IANA-IKECA^
# https://www.iana.org/assignments/ikev2-parameters/ikev2-parameters.xhtml#ikev2-parameters-21

* Security Considerations

This document describes a mechanism to add Traffic Flow
Confidentiality to IP traffic. Use of this mechanism is expected to
increase the security of the traffic being transported. Other than
the additional security afforded by using this mechanism, IP-TFS
utilizes the security protocols [[RFC4303]] and [[RFC7296]] and so their
security considerations apply to IP-TFS as well.

As noted previously in [[Congestion Controlled Mode]], for TFC to be
fully maintained the encapsulated traffic flow should not be
affecting network congestion in a predictable way, and if it would be
then non-congestion controlled mode use should be considered instead.

* Normative References
** RFC2119
** RFC4303
** RFC7296
** RFC8174
* Informative References
** AppCrypt
   :PROPERTIES:
    :REF_TITLE: Applied Cryptography: Protocols, Algorithms, and Source Code in C
    :REF_AUTHOR: Bruce Schneier
    :REF_DATE: 2017-11-01
    :END:
** RFC0791
** RFC1191
** RFC2474
** RFC2914
** RFC3168
** RFC4301
** RFC4342
** RFC4821
** RFC5348
** RFC7120
** RFC7510
** RFC8084
** RFC8126
** RFC8200
** RFC8201
** RFC8899
** I-D.iab-wire-image
* Example Of An Encapsulated IP Packet Flow

Below an example inner IP packet flow within the encapsulating tunnel
packet stream is shown. Notice how encapsulated IP packets can start
and end anywhere, and more than one or less than 1 may occur in a
single encapsulating packet.

# XXX Consider doing a timing diagram showing random paced input going
# into fixed rate output, maybe Y axis

#+CAPTION: Inner and Outer Packet Flow
#+begin_example
  Offset: 0        Offset: 100    Offset: 2900    Offset: 1400
 [ ESP1  (1500) ][ ESP2  (1500) ][ ESP3  (1500) ][ ESP4  (1500) ]
 [--800--][--800--][60][-240-][--4000----------------------][pad]
#+end_example

The encapsulated IP packet flow (lengths include IP header and
payload) is as follows: an 800 octet packet, an 800 octet packet, a 60
octet packet, a 240 octet packet, a 4000 octet packet.

The ~BlockOffset~ values in the 4 IP-TFS payload headers for this
packet flow would thus be: 0, 100, 2900, 1400 respectively. The first
encapsulating packet ESP1 has a zero ~BlockOffset~ which points at the
IP data block immediately following the IP-TFS header. The following
packet ESP2s ~BlockOffset~ points inward 100 octets to the start of the
60 octet data block. The third encapsulating packet ESP3 contains the
middle portion of the 4000 octet data block so the offset points past
its end and into the forth encapsulating packet. The fourth packet
ESP4s offset is 1400 pointing at the padding which follows the
completion of the continued 4000 octet packet.

* A Send and Loss Event Rate Calculation

The current best practice indicates that congestion control SHOULD be
done in a TCP friendly way. A TCP friendly congestion control algorithm
is described in [[RFC5348]]. For this IP-TFS use case (as with [[RFC4342]]) the
(fixed) packet size is used as the segment size for the algorithm. The
main formula in the algorithm for the send rate is then as follows:

#+begin_example
                              1
   X = -----------------------------------------------
       R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*p^2))
#+end_example

Where ~X~ is the send rate in packets per second, ~R~ is the
round trip time estimate and ~p~ is the loss event rate (the inverse
of which is provided by the receiver).

In addition the algorithm in [[RFC5348]] also uses an ~X_recv~ value (the
receiver's receive rate). For IP-TFS one MAY set this value according to
the sender's current tunnel send-rate (~X~).

The IP-TFS receiver, having the RTT estimate from the sender can use the
same method as described in [[RFC5348]] and [[RFC4342]] to collect the loss
intervals and calculate the loss event rate value using the weighted
average as indicated. The receiver communicates the inverse of this
value back to the sender in the AGGFRAG_PAYLOAD payload header field
~LossEventRate~.

The IP-TFS sender now has both the ~R~ and ~p~ values and can calculate
the correct sending rate. If following [[RFC5348]] the sender SHOULD also
use the slow start mechanism described therein when the IP-TFS SA is
first established.

* Comparisons of IP-TFS
  :PROPERTIES:
  :EXPORT_RFC_ASCII_TABLE: t
  :END:

** Comparing Overhead

*** IP-TFS Overhead

The overhead of IP-TFS is 40 bytes per outer packet. Therefore the
octet overhead per inner packet is 40 divided by the number of outer
packets required (fractional allowed). The overhead as a percentage of
inner packet size is a constant based on the Outer MTU size.

#+begin_example
   OH = 40 / Outer Payload Size / Inner Packet Size
   OH % of Inner Packet Size = 100 * OH / Inner Packet Size
   OH % of Inner Packet Size = 4000 / Outer Payload Size
#+end_example

#+BEGIN_CENTER
#+CAPTION: IP-TFS Overhead as Percentage of Inner Packet Size
#+TBLNAME: tfsohpct
|  Type | IP-TFS | IP-TFS | IP-TFS |
|   MTU |    576 |   1500 |   9000 |
| PSize |    536 |   1460 |   8960 |
|-------+--------+--------+--------|
|    40 |  7.46% |  2.74% |  0.45% |
|   576 |  7.46% |  2.74% |  0.45% |
|  1500 |  7.46% |  2.74% |  0.45% |
|  9000 |  7.46% |  2.74% |  0.45% |
#+TBLFM: @3$2..@3$>=@2-$tfso::@4$2..@>$>=4000/@3;%.2f%%
#+END_CENTER

*** ESP with Padding Overhead

The overhead per inner packet for constant-send-rate padded ESP
(i.e., traditional IPsec TFC) is 36 octets plus any padding, unless
fragmentation is required.

When fragmentation of the inner packet is required to fit in the
outer IPsec packet, overhead is the number of outer packets required
to carry the fragmented inner packet times both the inner IP overhead
(20) and the outer packet overhead (36) minus the initial inner IP
overhead plus any required tail padding in the last encapsulation
packet. The required tail padding is the number of required packets
times the difference of the Outer Payload Size and the IP Overhead
minus the Inner Payload Size. So:

#+begin_example
  Inner Paylaod Size = IP Packet Size - IP Overhead
  Outer Payload Size = MTU - IPsec Overhead

                Inner Payload Size
  NF0 = ----------------------------------
         Outer Payload Size - IP Overhead

  NF = CEILING(NF0)

  OH = NF * (IP Overhead + IPsec Overhead)
       - IP Overhead
       + NF * (Outer Payload Size - IP Overhead)
       - Inner Payload Size

  OH = NF * (IPsec Overhead + Outer Payload Size)
       - (IP Overhead + Inner Payload Size)

  OH = NF * (IPsec Overhead + Outer Payload Size)
       - Inner Packet Size
#+end_example

** Overhead Comparison

The following tables collect the overhead values for some common L3
MTU sizes in order to compare them. The first table is the number of
octets of overhead for a given L3 MTU sized packet. The second table
is the percentage of overhead in the same MTU sized packet.

#+CONSTANTS: etho=38 ipo=20 espoh=16 ipso=36 tfso=40

#+BEGIN_CENTER

#+BEGIN_NOEXPORT
# We need the number of packets for adding in L2 overhead later.
# No need to export this to the published document
#+CAPTION: Required Outer Packets
#+TBLNAME:reqdpackets
|   Type | ESP+Pad | ESP+Pad | ESP+Pad |      IP-TFS |      IP-TFS |       IP-TFS |
| L3 MTU |     576 |    1500 |    9000 |         576 |        1500 |         9000 |
|  PSize |     540 |    1464 |    8964 |         536 |        1460 |         8960 |
|--------+---------+---------+---------+-------------+-------------+--------------|
|     40 |       1 |       1 |       1 | 0.074626866 | 0.027397260 | 4.4642857e-3 |
|    128 |       1 |       1 |       1 |  0.23880597 | 0.087671233 |  0.014285714 |
|    256 |       1 |       1 |       1 |  0.47761194 |  0.17534247 |  0.028571429 |
|    536 |       1 |       1 |       1 |           1 |  0.36712329 |  0.059821429 |
|    576 |       2 |       1 |       1 |   1.0746269 |  0.39452055 |  0.064285714 |
|   1460 |       3 |       1 |       1 |   2.7238806 |           1 |   0.16294643 |
|   1500 |       3 |       2 |       1 |   2.7985075 |   1.0273973 |   0.16741071 |
|   8960 |      18 |       7 |       1 |   16.716418 |   6.1369863 |            1 |
|   9000 |      18 |       7 |       2 |   16.791045 |   6.1643836 |    1.0044643 |
#+TBLFM: @3$2..@3$4=@2-$ipso;p40::@3$5..@3$7=@2-$tfso;p40::@4$2..@>$4=if($1<=@3, ceil($1/@3), 1 + ceil(($1-@3)/(@3-$ipo)));p40::@4$5..@>$7=$1/@3;p40
#+END_NOEXPORT

#+CAPTION: Overhead comparison in octets
#+TBLNAME:obytes
|   Type | ESP+Pad | ESP+Pad | ESP+Pad | IP-TFS | IP-TFS | IP-TFS |
| L3 MTU |     576 |    1500 |    9000 |    576 |   1500 |   9000 |
|  PSize |     540 |    1464 |    8964 |    536 |   1460 |   8960 |
|--------+---------+---------+---------+--------+--------+--------|
|     40 |     500 |    1424 |    8924 |    3.0 |    1.1 |    0.2 |
|    128 |     412 |    1336 |    8836 |    9.6 |    3.5 |    0.6 |
|    256 |     284 |    1208 |    8708 |   19.1 |    7.0 |    1.1 |
|    536 |       4 |     928 |    8428 |   40.0 |   14.7 |    2.4 |
|    576 |     576 |     888 |    8388 |   43.0 |   15.8 |    2.6 |
|   1460 |     268 |       4 |    7504 |  109.0 |   40.0 |    6.5 |
|   1500 |     228 |    1500 |    7464 |  111.9 |   41.1 |    6.7 |
|   8960 |    1408 |    1540 |       4 |  668.7 |  245.5 |   40.0 |
|   9000 |    1368 |    1500 |    9000 |  671.6 |  246.6 |   40.2 |
#+TBLFM: @3$2..@3$4=@2-$ipso::@3$5..@3$7=@2-$tfso::@4$2..@>$4=if(@3 > $1, @3-$1, ceil(($1-$ipo)/(@3-$ipo)) * ($ipso + @3) - $1::@4$5..@>$7=$tfso/(@3/$1);%.1f

#+CAPTION: Overhead as Percentage of Inner Packet Size
#+TBLNAME:avail-pct
|  Type | ESP+Pad | ESP+Pad |  ESP+Pad | IP-TFS | IP-TFS | IP-TFS |
|   MTU |     576 |    1500 |     9000 |    576 |   1500 |   9000 |
| PSize |     540 |    1464 |     8964 |    536 |   1460 |   8960 |
|-------+---------+---------+----------+--------+--------+--------|
|    40 | 1250.0% | 3560.0% | 22310.0% |  7.46% |  2.74% |  0.45% |
|   128 |  321.9% | 1043.8% |  6903.1% |  7.46% |  2.74% |  0.45% |
|   256 |  110.9% |  471.9% |  3401.6% |  7.46% |  2.74% |  0.45% |
|   536 |    0.7% |  173.1% |  1572.4% |  7.46% |  2.74% |  0.45% |
|   576 |  100.0% |  154.2% |  1456.2% |  7.46% |  2.74% |  0.45% |
|  1460 |   18.4% |    0.3% |   514.0% |  7.46% |  2.74% |  0.45% |
|  1500 |   15.2% |  100.0% |   497.6% |  7.46% |  2.74% |  0.45% |
|  8960 |   15.7% |   17.2% |     0.0% |  7.46% |  2.74% |  0.45% |
|  9000 |   15.2% |   16.7% |   100.0% |  7.46% |  2.74% |  0.45% |
#+TBLFM: @3$2..@3$4=@2-$ipso::@3$5..@3$7=@2-$tfso::$1=remote(obytes,@@#$1)::@4$2..@>$4=100*remote(obytes,@@#$$#)/$1;%.1f%%::@4$5..@>$7=100*$tfso/(@3/$1)/$1;%.2f%%
#+END_CENTER

** Comparing Available Bandwidth

Another way to compare the two solutions is to look at the amount of
available bandwidth each solution provides. The following sections
consider and compare the percentage of available bandwidth. For the
sake of providing a well understood baseline normal (unencrypted)
Ethernet as well as normal ESP values are included.

*** Ethernet

In order to calculate the available bandwidth the per packet overhead
is calculated first. The total overhead of Ethernet is 14+4 octets of
header and CRC plus and additional 20 octets of framing (preamble,
start, and inter-packet gap) for a total of 38 octets. Additionally
the minimum payload is 46 octets.

# *** IP-TFS Bandwidth
# *** ESP with Padding Bandwidth

#+BEGIN_CENTER
#+BEGIN_NOEXPORT

#+TBLNAME: reqdbytes
| Size |   E+P |   E+P |   E+P |     IPTFS |     IPTFS |     IPTFS | Enet |  ESP |
|  MTU |   590 |  1514 |  9014 |       590 |      1514 |      9014 |  any |  any |
|   OH |    74 |    74 |    74 |        78 |        78 |        78 |   38 |   74 |
|------+-------+-------+-------+-----------+-----------+-----------+------+------|
|   40 |   614 |  1538 |  9038 | 45.820896 | 42.136986 | 40.348214 |   84 |  114 |
|  128 |   614 |  1538 |  9038 | 146.62687 | 134.83836 | 129.11428 |  166 |  202 |
|  256 |   614 |  1538 |  9038 | 293.25373 | 269.67672 | 258.22858 |  294 |  330 |
|  536 |   614 |  1538 |  9038 |       614 | 564.63562 | 540.66608 |  574 |  610 |
|  576 |  1228 |  1538 |  9038 | 659.82092 | 606.77261 | 581.01428 |  614 |  650 |
| 1460 |  1842 |  1538 |  9038 | 1672.4627 |      1538 | 1472.7098 | 1498 | 1534 |
| 1500 |  1842 |  3076 |  9038 | 1718.2836 | 1580.1370 | 1513.0580 | 1538 | 1574 |
| 8960 | 11052 | 10766 |  9038 | 10263.881 | 9438.6849 |      9038 | 8998 | 9034 |
| 9000 | 11052 | 10766 | 18076 | 10309.702 | 9480.8220 | 9078.3483 | 9038 | 9074 |
#+TBLFM: @2$2..@2$7=remote(obytes,@2$$#)+14::@3$2..@3$4=$etho + $ipso::@3$5..@3$7=$etho + $tfso::@4$2..@>$7=remote(reqdpackets,@@#$$#)*(@2+24);p40::@4$8..@>$>=max(84,$1+@I-1);p40
#+END_NOEXPORT

#+CAPTION: L2 Octets Per Packet
| Size | E + P | E + P | E + P | IPTFS | IPTFS | IPTFS | Enet |  ESP |
|  MTU |   590 |  1514 |  9014 |   590 |  1514 |  9014 |  any |  any |
|   OH |    74 |    74 |    74 |    78 |    78 |    78 |   38 |   74 |
|------+-------+-------+-------+-------+-------+-------+------+------|
|   40 |   614 |  1538 |  9038 |    45 |    42 |    40 |   84 |  114 |
|  128 |   614 |  1538 |  9038 |   146 |   134 |   129 |  166 |  202 |
|  256 |   614 |  1538 |  9038 |   293 |   269 |   258 |  294 |  330 |
|  536 |   614 |  1538 |  9038 |   614 |   564 |   540 |  574 |  610 |
|  576 |  1228 |  1538 |  9038 |   659 |   606 |   581 |  614 |  650 |
| 1460 |  1842 |  1538 |  9038 |  1672 |  1538 |  1472 | 1498 | 1534 |
| 1500 |  1842 |  3076 |  9038 |  1718 |  1580 |  1513 | 1538 | 1574 |
| 8960 | 11052 | 10766 |  9038 | 10263 |  9438 |  9038 | 8998 | 9034 |
| 9000 | 11052 | 10766 | 18076 | 10309 |  9480 |  9078 | 9038 | 9074 |
#+TBLFM: $1=remote(reqdbytes,$1)::@1$2..@3$>=remote(reqdbytes,@@#$$#)::@4$2..@>$4=remote(reqdbytes,@@#$$#)::@4$5..@>$7=remote(reqdbytes,@@#$$#);%d

#+BEGIN_NOEXPORT
#+TBLNAME: pps
| Size |     E + P |     E + P |     E + P |     IPTFS |     IPTFS |     IPTFS |      Enet |       ESP |
|  MTU |       590 |      1514 |      9014 |       590 |      1514 |      9014 |       any |       any |
|   OH |        74 |        74 |        74 |        78 |        78 |        78 |        38 |        74 |
|------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------|
|   40 | 2035830.6 | 812743.82 | 138304.93 | 27280130. | 29665150. | 30980306. | 14880952. | 10964912. |
|  128 | 2035830.6 | 812743.82 | 138304.93 | 8525040.5 | 9270359.0 | 9681345.9 | 7530120.5 | 6188118.8 |
|  256 | 2035830.6 | 812743.82 | 138304.93 | 4262520.4 | 4635179.5 | 4840672.6 | 4251700.7 | 3787878.8 |
|  536 | 2035830.6 | 812743.82 | 138304.93 | 2035830.6 | 2213817.1 | 2311963.1 | 2177700.3 | 2049180.3 |
|  576 | 1017915.3 | 812743.82 | 138304.93 | 1894453.4 | 2060079.8 | 2151410.1 | 2035830.6 | 1923076.9 |
| 1460 | 678610.21 | 812743.82 | 138304.93 | 747400.82 | 812743.82 | 848775.50 | 834445.93 | 814863.10 |
| 1500 | 678610.21 | 406371.91 | 138304.93 | 727470.13 | 791070.65 | 826141.50 | 812743.82 | 794155.02 |
| 8960 | 113101.70 | 116106.26 | 138304.93 | 121786.29 | 132433.70 | 138304.93 | 138919.76 | 138366.17 |
| 9000 | 113101.70 | 116106.26 | 69152.467 | 121245.02 | 131845.11 | 137690.24 | 138304.93 | 137756.23 |
#+TBLFM: @1$1..@>$1=remote(reqdbytes,@@#$$#)::@1$2..@3$>=remote(reqdbytes,@@#$$#)::@4$2..@>$>=(1e10/8)/remote(reqdbytes,@@#$$#)
#+END_NOEXPORT

# $8 = (1e10/8)/(max(46,$1)+38)
# $9 = (1e10/8)/($1+74)

#+CAPTION: Packets Per Second on 10G Ethernet
| Size | E + P | E + P | E + P | IPTFS | IPTFS | IPTFS | Enet  | ESP   |
|  MTU | 590   | 1514  | 9014  | 590   | 1514  | 9014  | any   | any   |
|   OH | 74    | 74    | 74    | 78    | 78    | 78    | 38    | 74    |
|------+-------+-------+-------+-------+-------+-------+-------+-------|
|   40 | 2.0M  | 0.8M  | 0.1M  | 27.3M | 29.7M | 31.0M | 14.9M | 11.0M |
|  128 | 2.0M  | 0.8M  | 0.1M  | 8.5M  | 9.3M  | 9.7M  | 7.5M  | 6.2M  |
|  256 | 2.0M  | 0.8M  | 0.1M  | 4.3M  | 4.6M  | 4.8M  | 4.3M  | 3.8M  |
|  536 | 2.0M  | 0.8M  | 0.1M  | 2.0M  | 2.2M  | 2.3M  | 2.2M  | 2.0M  |
|  576 | 1.0M  | 0.8M  | 0.1M  | 1.9M  | 2.1M  | 2.2M  | 2.0M  | 1.9M  |
| 1460 | 678K  | 812K  | 138K  | 747K  | 812K  | 848K  | 834K  | 814K  |
| 1500 | 678K  | 406K  | 138K  | 727K  | 791K  | 826K  | 812K  | 794K  |
| 8960 | 113K  | 116K  | 138K  | 121K  | 132K  | 138K  | 138K  | 138K  |
| 9000 | 113K  | 116K  | 69K   | 121K  | 131K  | 137K  | 138K  | 137K  |
#+TBLFM: $1=remote(pps,$1)::@1$2..@3$>=remote(pps,@@#$$#)::@4$2..@8$>=remote(pps,@@#$$#)/1000000;%.1fM::@9$2..@>$>=remote(pps,@@#$$#)/1000;%dK

#+CAPTION: Percentage of Bandwidth on 10G Ethernet
#+TBLNAME: bwpercent
| Size |  E + P |  E + P |  E + P |  IPTFS |  IPTFS |  IPTFS |   Enet |    ESP |
|      |    590 |   1514 |   9014 |    590 |   1514 |   9014 |    any |    any |
|      |     74 |     74 |     74 |     78 |     78 |     78 |     38 |     74 |
|------+--------+--------+--------+--------+--------+--------+--------+--------|
|   40 |  6.51% |  2.60% |  0.44% | 87.30% | 94.93% | 99.14% | 47.62% | 35.09% |
|  128 | 20.85% |  8.32% |  1.42% | 87.30% | 94.93% | 99.14% | 77.11% | 63.37% |
|  256 | 41.69% | 16.64% |  2.83% | 87.30% | 94.93% | 99.14% | 87.07% | 77.58% |
|  536 | 87.30% | 34.85% |  5.93% | 87.30% | 94.93% | 99.14% | 93.38% | 87.87% |
|  576 | 46.91% | 37.45% |  6.37% | 87.30% | 94.93% | 99.14% | 93.81% | 88.62% |
| 1460 | 79.26% | 94.93% | 16.15% | 87.30% | 94.93% | 99.14% | 97.46% | 95.18% |
| 1500 | 81.43% | 48.76% | 16.60% | 87.30% | 94.93% | 99.14% | 97.53% | 95.30% |
| 8960 | 81.07% | 83.22% | 99.14% | 87.30% | 94.93% | 99.14% | 99.58% | 99.18% |
| 9000 | 81.43% | 83.60% | 49.79% | 87.30% | 94.93% | 99.14% | 99.58% | 99.18% |
#+TBLFM: $1=remote(pps,$1)::@1$2..@3$>=remote(pps,@@#$$#)::@4$2..@>$9=(100*$1*remote(pps,@@#$$#))/(1e10/8);%.2f%%
#+END_CENTER

A sometimes unexpected result of using IP-TFS (or any packet
aggregating tunnel) is that, for small to medium sized packets, the
available bandwidth is actually greater than native Ethernet. This is
due to the reduction in Ethernet framing overhead. This increased
bandwidth is paid for with an increase in latency. This latency is
the time to send the unrelated octets in the outer tunnel frame. The
following table illustrates the latency for some common values on a
10G Ethernet link. The table also includes latency introduced by
padding if using ESP with padding.

#+BEGIN_CENTER
#+CAPTION: Added Latency
|      | ESP+Pad | ESP+Pad | IP-TFS  | IP-TFS  |
|      | 1500    | 9000    | 1500    | 9000    |
|      |         |         |         |         |
|------+---------+---------+---------+---------|
|   40 | 1.14 us | 7.14 us | 1.17 us | 7.17 us |
|  128 | 1.07 us | 7.07 us | 1.10 us | 7.10 us |
|  256 | 0.97 us | 6.97 us | 1.00 us | 7.00 us |
|  536 | 0.74 us | 6.74 us | 0.77 us | 6.77 us |
|  576 | 0.71 us | 6.71 us | 0.74 us | 6.74 us |
| 1460 | 0.00 us | 6.00 us | 0.04 us | 6.04 us |
| 1500 | 1.20 us | 5.97 us | 0.00 us | 6.00 us |
#+TBLFM: $2=(remote(obytes,@@#$3)*8)/10000;%.2f us::$3=(remote(obytes,@@#$4)*8)/10000;%.2f us::@4$4..@>$>=(((@2+4-$1)*8)/10000);%.2f us
#+END_CENTER

Notice that the latency values are very similar between the two
solutions; however, whereas IP-TFS provides for constant high
bandwidth, in some cases even exceeding native Ethernet, ESP with
padding often greatly reduces available bandwidth.

* Acknowledgements
We would like to thank Don Fedyk for help in reviewing and editing
this work. We would also like to thank Valery Smyslov for reviews and
suggestions for improvements as well as Joseph Touch for the
transport area review and suggested improvements.

* Contributors
The following people made significant contributions to this document.

#+begin_example
   Lou Berger
   LabN Consulting, L.L.C.

   Email: lberger@labn.net
#+end_example


# * Deriving TFRC Parameters

# The parameters required to implement the algorithm defined in
# [[RFC5348]] are: ~s~, ~R~, ~p~, ~t_RTO~ and ~b~. These values are used in
# the following formula to calculate the sending rate.

# #+begin_example
#                                 s
#    X_Bps = ----------------------------------------------------------
#            R*sqrt(2*b*p/3) + (t_RTO * (3*sqrt(3*b*p/8)*p*(1+32*p^2)))
# #+end_example

# Per [[RFC5348]] ~b~ can be set to ~1~ and t_RTO to ~4*R~ and the formula
# reduces to:

# #+begin_example
#                                 s
#    X_Bps = -----------------------------------------------
#            R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*p^2))
# #+end_example

# Per [[RFC5348]] also indicates that ~X_Bps~ can be specified as ~X_pps *
# s~ which then yields

# #+begin_example
#                                 1
#    X_Pps = -----------------------------------------------
#            R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*p^2))
# #+end_example

# The following sections describe how to derive the remaining values
# from the information provided by IP-TFS.

# ** Round-Trip Time

#    This value is in seconds. As described in Section 3.2.2, t_delay
#    gives the elapsed time at the receiver.

#    - Calculate a new round-trip sample:
# #+begin_example
#      R_sample = (t_now - t_recvdata) - t_delay.
# #+end_example
#    - Update the round-trip time estimate:
# #+begin_example
#       If no feedback has been received before {
#           R = R_sample;
#       } Else {
#           R = q*R + (1-q)*R_sample;
#       }
# #+end_example


# ** Loss Event Rate

#    Section 5 of [[RFC5348]] defines the calculation of the Loss Event
#    Rate ~p~.

# ** Example using minimum round-trip time

# The minimum round-trip time (~R~) for a link is 2 times the
# transmission time for a packet plus some possible small but non-zero
# processing time. Let's consider 1500B (12000 bit) packets. If we can
# transmit ~X~ bits per second, then we can transmit ~X/12000~ pps, and
# so ~1/(X/12000)~ or ~12000/X~ is the transmit time of one packet and
# the min ~R~ is twice that (~24000/X~).

# #+BEGIN_CENTER
# | Link Speed |     pps |      R | pprtt |
# |------------+---------+--------+-------|
# | 10M        |  833.33 |  .0024 |       |
# | 100M       | 8333.33 | .00024 |       |
# | 1GE        |         | 2.4e-5 |       |
# | 10GE       |         | 2.4e-6 |       |
# | 100GE      |         | 2.4e-7 |       |
# #+END_CENTER

# # Now let's consider a loss rate of 1 packet every second on a 10M link.
# # p = 1/832

# #+begin_src python :results output :var linkspeed=1000000 :var psize=1500 :var lossint=(- (expt 2 32) 1) exports: none
#   from math import sqrt
#   linkspeed *= 1000000
#   psize *= 8.
#   print("psize:", psize)
#   prate = linkspeed / psize
#   print("prate:", prate)
#   # R = 10 * 2. * psize / linkspeed
#   R = .0001
#   print("R:", R)
#   p = 1. / lossint
#   print("p:", p)
#   denom = R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*(p**2)))
#   print("denom:", denom)
#   pps = 1. / denom
#   print(pps)
#   # return pps
# #+end_src

# #+RESULTS:
# : psize: 12000.0
# : prate: 83333333.33333333
# : R: 0.0001
# : p: 2.3283064370807974e-10
# : denom: 1.2458749126186029e-09
# : 802648797.13982

# #+begin_example
#                                 1
#    X_Pps = -----------------------------------------------
#            R * (sqrt(2*.5/3) + 12*sqrt(3*.5/8)*.5*(1+32*.5^2))

#                                 1
#    X_Pps = -----------------------------------------------
#            R * (sqrt(1/3) + 12*sqrt(.1875) * .5 * (9) )

#                            1
#    X_Pps = ----------------------------------
#             R * (sqrt(1/3) + 54*sqrt(.1875))

#                                 1
#    X_Pps = -------------------------------------
#              R * (0.577350269189+23.3826859022)

#             23.9600361714
#                                 1
#    X_Pps = -----------------------------------------------
#            R * (sqrt(2*2/3) + 12*sqrt(3*2/8)*2*(1+32*2^2))

# 2682.369351.15470053838065


# R * (1.15470053838 + 12*0.866025403784*2*(1+128))
# (1.15470053838 + 12*0.866025403784*2*(1+128))

# 2682.36935065 * .0024
# 6.43768644156

#                   1
#    X_Pps = ----------------
#            R * (sqrt(2*0/3)

# #+end_example
