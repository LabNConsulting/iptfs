# -*- fill-column: 69; org-confirm-babel-evaluate: nil -*-
#+STARTUP: align entitiespretty hidestars inlineimages latexpreview noindent showall
#
#+TITLE: IP Traffic Flow Security
#+AUTHOR: Christian Hopps
#+EMAIL: chopps@chopps.org
#+AFFILIATION: LabN Consulting, L.L.C.
#
#+RFC_NAME: draft-hopps-ipsecme-iptfs
#+RFC_VERSION: 01
#+RFC_XML_VERSION: 2
#+RFC_ASCII_TABLE: t
#
# Do: title, table-of-contents ::fixed-width-sections |tables
# Do: ^:sup/sub with curly -:special-strings *:emphasis
# Don't: prop:no-prop-drawers \n:preserve-linebreaks ':use-smart-quotes
#+OPTIONS: prop:nil title:t toc:t \n:nil ::t |:t ^:{} -:t *:t ':nil


#+begin_abstract
This document describes a mechanism to enhance IPsec traffic flow
security by adding traffic flow confidentiality to encrypted IP
encapsulated traffic. Traffic flow confidentiality is provided by
obscuring the size and frequency of IP traffic using a fixed-sized,
constant-send-rate IPsec tunnel. The solution allows for congestion
control as well.
#+end_abstract


* Introduction

Traffic Analysis ([[RFC4301]], [[AppCrypt]]) is the act of extracting
information about data being sent through a network. While one may
directly obscure the data through the use of encryption [[RFC4303]],
the traffic pattern itself exposes information due to variations in
it's shape and timing ([[I-D.iab-wire-image]], [[AppCrypt]]).
Hiding the size and frequency of traffic is referred to as Traffic
Flow Confidentiality (TFC) per [[RFC4303]].

[[RFC4303]] provides for TFC by allowing padding to be added to encrypted
IP packets and allowing for sending all-pad packets (indicated using
protocol 59). This method has the major limitation that it can
significantly under-utilize the available bandwidth.

The IP-TFS solution provides for full TFC without the aforementioned
bandwidth limitation. To do this we use a constant-send-rate IPsec
[[RFC4303]] tunnel with fixed-sized encapsulating packets; however,
these fixed-sized packets can contain partial, full or multiple IP
packets to maximize the bandwidth of the tunnel.

For a comparison of the overhead of IP-TFS with the RFC4303
prescribed TFC solution see [[Comparisons of IP-TFS]].

Additionally, IP-TFS provides for dealing with network congestion
[[RFC2914]]. This is important for when the IP-TFS user is not in full
control of the domain through which the IP-TFS tunnel path flows.

** Terminology & Concepts

The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
"SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in
[[RFC2119]] [[RFC8174]] when, and only when, they appear in all capitals,
as shown here.

This document assumes familiarity with IP security concepts described
in [[RFC4301]].

* The IP-TFS Tunnel

As mentioned in [[Introduction]] IP-TFS utilizes an IPsec [[RFC4303]]
tunnel as it's transport. To provide for full TFC we send fixed-sized
encapsulating packets at a constant rate on the tunnel.

The primary input to the tunnel algorithm is the requested bandwidth
of the tunnel. Two values are then required to provide for this
bandwidth, the fixed size of the encapsulating packets, and rate at
which to send them.

The fixed packet size may either be specified manually or can be
determined through the use of Path MTU discovery [[RFC1191]] and [[RFC8201]].

Given the encapsulating packet size and the requested tunnel
bandwidth, the correct packet send rate can be calculated. The packet
send rate is the requested bandwidth divided by the payload size of
the encapsulating packet.

The egress of the IP-TFS tunnel SHOULD NOT impose any restrictions on
tunnel packet size or arrival rate. Packet size and send rate is
entirely the function of the ingress (sending) side of the IP-TFS
tunnel. Indeed, the ingress (sending) side of the IP-TFS tunnel MUST
be allowed by the egress side to vary the size and rate at which it
sends encapsulating packets, including sending them larger, smaller,
faster or slower than the requested size and rate.

** Tunnel Content

As previously mentioned, one issue with the TFC padding solution in
[[RFC4303]] is the large amount of wasted bandwidth as only one IP
packet can be sent per encapsulating packet. In order to maximize
bandwidth IP-TFS breaks this one-to-one association.

With IP-TFS we fragment as well as aggregate the inner IP traffic
flow into fixed-sized encapsulating IP tunnel packets. We only pad
the tunnel packets if there is no data available to be sent at the
time of tunnel packet transmission.

In order to do this we create a new payload data type identified with
a new IP protocol number IPTFS_PROTOCOL (TBD). A payload of
IPTFS_PROTOCOL type is comprised of a 32 bit header followed by
either a partial, a full or multiple partial or full data-blocks.

*** IPSec/ESP Payload

#+CAPTION: Layout of IP-TFS IPSec Packet
#+begin_example
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . Outer Encapsulating Header ...                                .
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . ESP Header...                                                 .
 +---------------------------------------------------------------+
 |               ...            :           BlockOffset          |
 +---------------------------------------------------------------+
 :                  [Optional Congestion Info]                   :
 +---------------------------------------------------------------+
 |       Data Blocks Payload ...                                 ~
 ~                                                               ~
 ~                                                               |
 +---------------------------------------------------------------|
 . ESP Trailer...                                                .
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
#+end_example

The BlockOffset value is either zero or some offset into or past the
end of the data blocks payload data. If the value is zero it means
that a new data-block immediately follows the fixed header (i.e., the
BlockOffset value). Conversely, if the BlockOffset value is non-zero
it points at the start of the next data block. The BlockOffset can
point past the end of the data block payload data, this means that
the next data-block occurs in a subsequent encapsulating packet. When
the BlockOffset is non-zero the data immediately following the header
belongs to the previous data-block that is still being re-assembled.

*** Data-Blocks

#+CAPTION: Layout of IP-TFS data block
#+begin_example
 +---------------------------------------------------------------+
 | Type  | rest of IPv4, IPv6 or pad.
 +--------
#+end_example

A data-block is defined by a 4-bit type code followed by the data
block data. The type values have been carefully chosen to coincide
with the IPv4/IPv6 version field values so that no per-data-block
type overhead is required to encapsulate an IP packet. Likewise, the
length of the data block is extracted from the encapsulated IPv4 or
IPv6 packet's length field.

*** No Implicit Padding

It's worth noting that there is no need for implicit pads at the end
of an encapsulating packet. Even when the start of a data block
occurs near the end of a encapsulating packet such that there is no
room for the length field of the encapsulated header to be included
in the current encapsulating packet, the fact that the length comes
at a known location and as is guaranteed to be present is enough to
fetch the length field from the subsequent encapsulating packet
payload.

*** IP Header Value Mapping

[[RFC4301]] provides some direction on when and how to map various
values from an inner IP header to the outer encapsulating header,
namely the Don't-Fragment (DF) bit ([[RFC0791]] and [[RFC8200]]), the
Differentiated Services (DS) field [[RFC2474]] and the Explicit
Congestion Notification (ECN) field [[RFC3168]]. Unlike [[RFC4301]] with
IP-TFS we may and often will be encapsulating more than 1 IP packet
per ESP packet. To deal with this we further restrict these mappings.
In particular we never map the inner DF bit as it is unrelated to the
IP-TFS tunnel functionality; we never directly fragment the inner
packets and the inner packets will not affect the fragmentation of
the outer encapsulation packets. Likewise, the ECN value need not be
mapped as any congestion related to the constant-send-rate IP-TFS
tunnel is unrelated (by design!) to the inner traffic flow. Finally,
by default the DS field SHOULD NOT be copied although an
implementation MAY choose to allow for configuration to override this
behavior. An implementation SHOULD also allow the DS value to be set
by configuration.

** Exclusive SA Use

It is not the intention of this specification to allow for mixed use
of an IPsec SA. In other words, an SA that is created for IP-TFS is
exclusively for IP-TFS use and MUST NOT have non-IP-TFS payloads such
as IP (IP protocol 4), TCP transport (IP protocol 6), or ESP pad
packets (protocol 59) intermixed with IP-TFS (IP protocol TBD)
payloads. While it's possible to envision making the algorithm work
in the presence of sequence number skips in the IP-TFS payload
stream, the added complexity is not deemed worthwhile. Other IPsec
uses can configure and use their own SAs.

** Initiation of TFS mode

While normally a user will configure their IPsec tunnel to operate in
IP-TFS mode to start, we also allow IP-TFS mode to be enabled post-SA
creation. This may be useful for debugging or other purposes. In this
late enabled mode the receiver would switch to IP-TFS mode on receipt
of the first ESP payload with the IPTFS_PROTOCOL indicated as the
payload type.

** Example of an encapsulated IP packet flow

Below we show an example inner IP packet flow within the
encapsulating tunnel packet stream. Notice how encapsulated IP
packets can start and end anywhere, and more than one or less than 1
may occur in a single encapsulating packet.

# XXX Consider doing a timing diagram showing random paced input going
# into fixed rate output, maybe Y axis

#+CAPTION: Inner and Outer Packet Flow
#+begin_example
  Offset: 0        Offset: 100    Offset: 2900    Offset: 1400
 [ ESP1  (1500) ][ ESP2  (1500) ][ ESP3  (1500) ][ ESP4  (1500) ]
 [--800--][--800--][60][-240-][--4000----------------------][pad]
#+end_example


The encapsulated IP packet flow (lengths include IP header and
payload) is as follows: an 800 octet packet, an 800 octet packet, a 60
octet packet, a 240 octet packet, a 4000 octet packet.

The BlockOffset values in the 4 IP-TFS payload headers for this
packet flow would thus be: 0, 100, 2900, 1400 respectively. The first
encapsulating packet ESP1 has a zero BlockOffset which points at the
IP data block immediately following the IP-TFS header. The following
packet ESP2s BlockOffset points inward 100 octets to the start of the
60 octet data block. The third encapsulating packet ESP3 contains the
middle portion of the 4000 octet data block so the offset points past
its end and into the forth encapsulating packet. The fourth packet
ESP4s offset is 1400 pointing at the padding which follows the
completion of the continued 4000 octet packet.

Having the BlockOffset always point at the next available data block
allows for quick recovery with minimal inner packet loss in the
presence of outer encapsulating packet loss.

** Modes of operation

Just as with normal IPsec/ESP tunnels, IP-TFS tunnels are
unidirectional; however, unless statically configured they will
utilize an associated bidirectional IKE connection. Bidirectional
IP-TFS functionality is achieved by setting up 2 IP-TFS tunnels, one
in either direction.

An IP-TFS tunnel can operate in 2 modes, a non-congestion controlled
mode and congestion controlled mode.

*** Non-Congestion Controlled Mode

In the non-congestion controlled mode IP-TFS sends fixed-sized
packets at a constant rate. The packet send rate is constant and is
not automatically adjusted regardless of any network congestion
(i.e., packet loss).

For similar reasons as given in [[RFC7510]] the non-congestion
controlled mode should only be used where the user has full
administrative control over the path the tunnel will take. This is
required so the user can guarantee the bandwidth and also be sure as
to not be negatively affecting network congestion [[RFC2914]]. In this
case packet loss should be reported to the administrator (e.g.,
via syslog, YANG notification, SNMP traps, etc) so that any
failures due to a lack of bandwidth can be corrected.

*** Congestion Controlled Mode

With the congestion controlled mode, IP-TFS adapts to network
congestion by lowering the packet send rate to accommodate the
congestion, as well as raising the rate when congestion subsides.

If congestion were handled in the network on a octet level we might
consider lowering the IPsec (encapsulation) packet size to adapt;
however, as congestion is normally handled in the network by dropping
packets we instead choose to lower the frequency we send our fixed
sized packets. This choice also minimizes transport overhead.

The output of the congestion control algorithm will adjust the rate
at which the ingress sends packets. While this document does not
require a specific congestion control algorithm, best current
practice RECOMMENDS that the algorithm conform to [[RFC5348]]. Congestion
control principles are documented in [[RFC2914]] as well. One algorithm
that is well suited for IP-TFS (i.e., designed for fixed-size packet
and send rate varied based on congestion) is documented in [[RFC4342]].

Generally, the input required for a TCP friendly rate control
algorithm ([[RFC5348]]) is the loss event rate and an estimated
round-trip time (RTT). These values are provided by IP-TFS using the
congestion information reports described in [[Congestion Information]].
In particular these values are sufficient to implement the algorithm
described in [[RFC5348]]. [[Deriving TFRC Parameters]] describes how the data
provided by IP-TFS congestion information may be used to derive the
values required in [[RFC5348]].

When an implementation is choosing a congestion control algorithm (or
a selection of algorithms) one should remember that IP-TFS is not
providing for reliable delivery of IP traffic, and so per packet ACKs
are not required and are not provided.

It's worth noting that the variable send-rate of a congestion
controlled IP-TFS tunnel, is not private; however, this send-rate is
being driven by network congestion, and as long as the encapsulated
(inner) traffic flow shape and timing are not directly affecting the
(outer) network congestion, the variations in the tunnel rate will
not weaken the provided inner traffic flow confidentiality.

**** Circuit Breakers

In additional to congestion control, implementations MAY choose to
define and implement circuit breakers [[RFC8084]] as a recovery method
of last resort. Enabling circuit breakers is also a reason a user may
wish to enable congestion information reports even when using the
non-congestion controlled mode of operation. The definition of
circuit breakers are outside the scope of this document.

* Congestion Information

In order to support the congestion control mode, the sender, in
general, needs to know the loss event rate and also be able to
approximate the RTT ([[RFC5348]]). In order to obtain these values the
sender periodically requests congestion information from the receiver
using an IKEv2 information exchange [[RFC7296]].

In order to calculate the loss rate, the congestion information from
the receiver includes a packet drop count indicating the number of
packet drops that have occurred over a sequence of packets. The
sequence of packets is identified by the start and end ESP sequence
numbers. The reported sequence start is either an initial value (1)
or 1 beyond the end sequence number of the prior congestion
information report the sender supplied. The loss rate then is the
number of packet drops divided by the time interval between sending
the start and end packets as indicated by the provided sequence
number range. The time interval is simply the number of packets in
the range multiplied by the current packet send rate.

The sender must also be able to approximate a round-trip time. To do
this the sender utilizes the IKEv2 information exchange. In order to
account for possible retransmissions of the IKEv2 information
request, the sender includes a send count in its request. The
receiver echo's this value and in it's reply. Additionally the
receiver supplies an estimate of it's control plane overhead. This
overhead estimate should be the as amount of time between receipt of
the IKEv2 information request and the reply being sent (i.e., the
amount of time it took the receiver to process the request), This
estimate SHOULD be as close to but never longer than the actual time.
The sender then subtracts this estimate from the real-world
round-trip time of the exchange to arrive at the actual round-trip
time estimate for the tunnel.

** ECN Support

In additional to normal packet loss information IP-TFS supports use
of the ECN bits in the encapsulating IP header [[RFC3168]] for
identifying congestion. If ECN use is enabled and a packet arrives at
the egress endpoint with the Congestion Experienced (CE) value set,
then the receiver records that packet as being dropped, although it
does not drop it. When the CE information is used to calculate the
packet drop count the receiver also sets the E bit in the congestion
information notification data. In order to respond quickly to the
congestion indication the receiver MAY immediately send a congestion
information notification to the sender upon receiving a packet with
the CE indication. This additional immediate send SHOULD only be done
once per normal congestion information sending interval though.

As noted in [[RFC3168]] the ECN bits are not protected by IPsec and
thus may constitute a covert channel. For this reason ECN use SHOULD
NOT be enabled by default.

* Configuration

IP-TFS is meant to be deployable with a minimal amount of
configuration. All IP-TFS specific configuration (i.e., in addition
to the underlying IPsec tunnel configuration) should be able to be
specified at the (unidirectional) tunnel ingress (sending) side. It
is intended that non-IKEv2 operation is supported with local static
configuration.

** Bandwidth

Bandwidth is a local configuration option. For non-congestion
controlled mode the bandwidth SHOULD be configured. For
congestion controlled mode one can configure the bandwidth
or have no configuration and let congestion control discover the
maximum bandwidth available. No standardized configuration method is
required.

** Fixed Packet Size

The fixed packet size to be used for the tunnel encapsulation packets
can be configured manually or can be automatically determined using
Path MTU discovery (see [[RFC1191]] and [[RFC8201]]). No standardized
configuration method is required.

** Congestion Control

Congestion control is a local configuration option. No standardized
configuration method is required.

* Packet and Data Formats
** IPSec
*** Payload Format
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |V|C|E|      Reserved           |          BlockOffset          |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 :              RTT              :             Delay             :
 :...............................................................:
 :                          LossEventRate                        :
 :...............................................................:
 :                           LastSeqNum                          :
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |       DataBlocks ...
 +-+-+-+-+-+-+-+-+-+-+-
#+end_example

- V :: A 1 bit version field that MUST be set to zero. If received as
       one the packet MUST be dropped.
- C :: A 1 bit value if set indicates the inclusion of the optional
       congestion information values ~RTT~, ~LossEventRate~ and
       ~LastSeqNum~.
- E :: A 1 bit value if set indicates that Congestion Experienced
       (CE) ECN bits were received and used to determine the loss
       intervals which the receiver used to calculate the
       reported ~LossEventRate~.
- Reserved :: A 13 bit field set to 0 and ignored on receipt.
- BlockOffset :: A 16 bit unsigned integer counting the number of
                 octets following the header fields before the next
                 data block. It can also point past the end of the
                 containing packet in which case the data entirely
                 belongs to the previous data block. If the offset
                 extends into subsequent packets the subsequent
                 IP-TFS headers are not counted by this value.
- RTT :: An optional 16 bit value specifying the sender's current
         round-trip time estimate in milliseconds. The value MAY be
         zero prior to the sender having calculated a round-trip time
         estimate.
- Delay :: An optional 16 bit value specifying the delay in
           milliseconds incurred between the receiver receiving the
           ~LastSeqNum~ packet and the sending of this acknowledgement
           of it. This value is used by the sender to calculate it's
           round-trip time estimate.
- LossEventRate :: An optional 32 bit value specifying the inverse of
                   the current loss event rate as calculated by the
                   receiver. A value of zero indicates no loss.
                   Otherwise the loss event rate is 1 / ~LossEventRate~.
- LastSeqNum :: An optional 32 bit value containing the lower 32 bits
                of the largest sequence number last received. This is
                the latest in the sequence not necessarily the most
                recent (in the case of re-ordering of packets it may
                be less recent). When determining largest when 64 bit
                extended sequence numbers are in use, the upper 32
                bits should be used during the comparison.
- DataBlocks :: Variable number of octets that begin with the start
                or continuation of a previous data block followed by
                zero or more additional data blocks.

*** Data Blocks
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 | Type  | IPv4, IPv6 or pad...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Type :: A 4 bit field where 0x0 identifies a pad data block, 0x4
          indicates an IPv4 data block, and 0x6 indicates an IPv6
          data block.

**** IPv4 Data Block
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  0x4  |  IHL  |  TypeOfService  |         TotalLength         |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 | Rest of the inner packet ...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#+end_example

These values are the actual values within the encapsulated IPv4
header. In other words, the start of this data block is the start of
the encapsulated IP packet.

- Type :: A 4 bit value of 0x4 indicating IPv4 (i.e., first nibble of
          the IPv4 packet).
- TotalLength :: The 16 bit unsigned integer length field of the IPv4
                 inner packet.

**** IPv6 Data Block
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  0x6  | TrafficClass  |               FlowLabel               |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |          TotalLength          | Rest of the inner packet ...
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#+end_example

These values are the actual values within the encapsulated IPv6
header. In other words, the start of this data block is the start of
the encapsulated IP packet.

- Type :: A 4 bit value of 0x6 indicating IPv6 (i.e., first nibble of
          the IPv6 packet).
- TotalLength :: The 16 bit unsigned integer length field of the
                 inner IPv6 inner packet.

**** Pad Data Block
#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  0x0  | Padding ...
 +-+-+-+-+-+-+-+-+-+-+-
#+end_example

- Type :: A 4 bit value of 0x0 indicating a padding data block.
- Padding :: extends to end of the encapsulating packet.

** IKEv2

*** IKEv2 IP-TFS Supported Payload Type (TBD)

The following defines the IP-TFS supported payload IPTFS_SUPPORT.
The presence of this payload indicates that the node is capable of
receiving IP-TFS format ESP payloads (IPTFS_PROTOCOL). It should be
included during the IKEv2 [[RFC7296]] IKE_AUTH exchange.

The first 4 octets are the standard generic payload header fields
defined in [[RFC7296]]. The Payload Type value is TBD.

#+begin_example
                      1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 | Next Payload  |C|  RESERVED   |         Payload Length        |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |D|N| ResvFlags |
 +-+-+-+-+-+-+-+-+
#+end_example

- Payload Length :: 2 octet length set to 5.
- D :: 1 bit value that if set indicates fragmentation is not
       supported by the receiver.
- N :: 1 bit value that if set indicates congestion control is
       not supported by the receiver.
- ResvFlags :: 6 bits set to 0.

* IANA Considerations

This document requests a protocol number IPTFS_PROTOCOL be allocated
by IANA from "Assigned Internet Protocol Numbers" registry for
identifying the IP-TFS ESP payload format.

  - Type :: TBD
  - Description :: IP-TFS ESP payload format.
  - Reference :: This document

# ^IANA-PN^ https://www.iana.org/assignments/protocol-numbers

Additionally this document requests an IKEv2 payload type
IPTFS_SUPPORT (TBD) be allocated by IANA from "IKEv2 Payload Types"
registry.

  - Type :: TBD
  - Description :: Indicates support for being an IPTFS receiving
                   tunnel endpoint.
  - Reference :: This document

# ^IANA-IKECA^
# https://www.iana.org/assignments/ikev2-parameters/ikev2-parameters.xhtml#ikev2-parameters-21

* Security Considerations

This document describes a mechanism to add Traffic Flow
Confidentiality to IP traffic. Use of this mechanism is expected to
increase the security of the traffic being transported. Other than
the additional security afforded by using this mechanism, IP-TFS
utilizes the security protocols [[RFC4303]] and [[RFC7296]] and so their
security considerations apply to IP-TFS as well.

As noted previously in [[Congestion Controlled Mode]], for TFC to be
fully maintained the encapsulated traffic flow should not be
affecting network congestion in a predictable way, and if it would be
then non-congestion controlled mode use should be considered instead.

* Normative References
** RFC2119
** RFC4303
** RFC7296
** RFC8174
* Informative References
** AppCrypt
   :PROPERTIES:
    :REF_TITLE: Applied Cryptography: Protocols, Algorithms, and Source Code in C
    :REF_AUTHOR: Bruce Schneier
    :REF_DATE: 2017-11-01
    :END:
** RFC0791
** RFC1191
** RFC2474
** RFC2914
** RFC3168
** RFC4301
** RFC4342
** RFC5348
** RFC7510
** RFC8084
** RFC8200
** RFC8201
** I-D.iab-wire-image

* Comparisons of IP-TFS
  :PROPERTIES:
  :EXPORT_RFC_ASCII_TABLE: t
  :END:

** Comparing Overhead

*** IP-TFS Overhead

The overhead of IP-TFS is 40 bytes per outer packet. Therefore the
octet overhead per inner packet is 40 divided by the number of outer
packets required (fractional allowed). The overhead as a percentage of
inner packet size is a constant based on the Outer MTU size.

#+begin_example
   OH = 40 / Outer Payload Size / Inner Packet Size
   OH % of Inner Packet Size = 100 * OH / Inner Packet Size
   OH % of Inner Packet Size = 4000 / Outer Payload Size
#+end_example

#+BEGIN_CENTER
#+CAPTION: IP-TFS Overhead as Percentage of Inner Packet Size
#+TBLNAME: tfsohpct
|  Type | IP-TFS | IP-TFS | IP-TFS |
|   MTU |    576 |   1500 |   9000 |
| PSize |    536 |   1460 |   8960 |
|-------+--------+--------+--------|
|    40 |  7.46% |  2.74% |  0.45% |
|   576 |  7.46% |  2.74% |  0.45% |
|  1500 |  7.46% |  2.74% |  0.45% |
|  9000 |  7.46% |  2.74% |  0.45% |
#+TBLFM: @3$2..@3$>=@2-$tfso::@4$2..@>$>=4000/@3;%.2f%%
#+END_CENTER

*** ESP with Padding Overhead

The overhead per inner packet for constant-send-rate padded ESP
(i.e., traditional IPSec TFC) is 36 octets plus any padding, unless
fragmentation is required.

When fragmentation of the inner packet is required to fit in the
outer IPsec packet, overhead is the number of outer packets required
to carry the fragmented inner packet times both the inner IP overhead
(20) and the outer packet overhead (36) minus the initial inner IP
overhead plus any required tail padding in the last encapsulation
packet. The required tail padding is the number of required packets
times the difference of the Outer Payload Size and the IP Overhead
minus the the Inner Payload Size. So:

#+begin_example
  Inner Paylaod Size = IP Packet Size - IP Overhead
  Outer Payload Size = MTU - IPSec Overhead

                Inner Payload Size
  NF0 = ----------------------------------
         Outer Payload Size - IP Overhead

  NF = CEILING(NF0)

  OH = NF * (IP Overhead + IPsec Overhead)
       - IP Overhead
       + NF * (Outer Payload Size - IP Overhead)
       - Inner Payload Size

  OH = NF * (IPSec Overhead + Outer Payload Size)
       - (IP Overhead + Inner Payload Size)

  OH = NF * (IPSec Overhead + Outer Payload Size)
       - Inner Packet Size
#+end_example

** Overhead Comparison

The following tables collect the overhead values for some common L3
MTU sizes in order to compare them. The first table is the number of
octets of overhead for a given L3 MTU sized packet. The second table
is the percentage of overhead in the same MTU sized packet.

#+CONSTANTS: etho=38 ipo=20 espoh=16 ipso=36 tfso=40

#+BEGIN_CENTER

#+BEGIN_NOEXPORT
# We need the number of packets for adding in L2 overhead later.
# No need to export this to the published document
#+CAPTION: Required Outer Packets
#+TBLNAME:reqdpackets
|   Type | ESP+Pad | ESP+Pad | ESP+Pad |      IP-TFS |      IP-TFS |       IP-TFS |
| L3 MTU |     576 |    1500 |    9000 |         576 |        1500 |         9000 |
|  PSize |     540 |    1464 |    8964 |         536 |        1460 |         8960 |
|--------+---------+---------+---------+-------------+-------------+--------------|
|     40 |       1 |       1 |       1 | 0.074626866 | 0.027397260 | 4.4642857e-3 |
|    128 |       1 |       1 |       1 |  0.23880597 | 0.087671233 |  0.014285714 |
|    256 |       1 |       1 |       1 |  0.47761194 |  0.17534247 |  0.028571429 |
|    536 |       1 |       1 |       1 |           1 |  0.36712329 |  0.059821429 |
|    576 |       2 |       1 |       1 |   1.0746269 |  0.39452055 |  0.064285714 |
|   1460 |       3 |       1 |       1 |   2.7238806 |           1 |   0.16294643 |
|   1500 |       3 |       2 |       1 |   2.7985075 |   1.0273973 |   0.16741071 |
|   8960 |      18 |       7 |       1 |   16.716418 |   6.1369863 |            1 |
|   9000 |      18 |       7 |       2 |   16.791045 |   6.1643836 |    1.0044643 |
#+TBLFM: @3$2..@3$4=@2-$ipso;p40::@3$5..@3$7=@2-$tfso;p40::@4$2..@>$4=if($1<=@3, ceil($1/@3), 1 + ceil(($1-@3)/(@3-$ipo)));p40::@4$5..@>$7=$1/@3;p40
#+END_NOEXPORT

#+CAPTION: Overhead comparison in octets
#+TBLNAME:obytes
|   Type | ESP+Pad | ESP+Pad | ESP+Pad | IP-TFS | IP-TFS | IP-TFS |
| L3 MTU |     576 |    1500 |    9000 |    576 |   1500 |   9000 |
|  PSize |     540 |    1464 |    8964 |    536 |   1460 |   8960 |
|--------+---------+---------+---------+--------+--------+--------|
|     40 |     500 |    1424 |    8924 |    3.0 |    1.1 |    0.2 |
|    128 |     412 |    1336 |    8836 |    9.6 |    3.5 |    0.6 |
|    256 |     284 |    1208 |    8708 |   19.1 |    7.0 |    1.1 |
|    536 |       4 |     928 |    8428 |   40.0 |   14.7 |    2.4 |
|    576 |     576 |     888 |    8388 |   43.0 |   15.8 |    2.6 |
|   1460 |     268 |       4 |    7504 |  109.0 |   40.0 |    6.5 |
|   1500 |     228 |    1500 |    7464 |  111.9 |   41.1 |    6.7 |
|   8960 |    1408 |    1540 |       4 |  668.7 |  245.5 |   40.0 |
|   9000 |    1368 |    1500 |    9000 |  671.6 |  246.6 |   40.2 |
#+TBLFM: @3$2..@3$4=@2-$ipso::@3$5..@3$7=@2-$tfso::@4$2..@>$4=if(@3 > $1, @3-$1, ceil(($1-$ipo)/(@3-$ipo)) * ($ipso + @3) - $1::@4$5..@>$7=$tfso/(@3/$1);%.1f

#+CAPTION: Overhead as Percentage of Inner Packet Size
#+TBLNAME:avail-pct
|  Type | ESP+Pad | ESP+Pad |  ESP+Pad | IP-TFS | IP-TFS | IP-TFS |
|   MTU |     576 |    1500 |     9000 |    576 |   1500 |   9000 |
| PSize |     540 |    1464 |     8964 |    536 |   1460 |   8960 |
|-------+---------+---------+----------+--------+--------+--------|
|    40 | 1250.0% | 3560.0% | 22310.0% |  7.46% |  2.74% |  0.45% |
|   128 |  321.9% | 1043.8% |  6903.1% |  7.46% |  2.74% |  0.45% |
|   256 |  110.9% |  471.9% |  3401.6% |  7.46% |  2.74% |  0.45% |
|   536 |    0.7% |  173.1% |  1572.4% |  7.46% |  2.74% |  0.45% |
|   576 |  100.0% |  154.2% |  1456.2% |  7.46% |  2.74% |  0.45% |
|  1460 |   18.4% |    0.3% |   514.0% |  7.46% |  2.74% |  0.45% |
|  1500 |   15.2% |  100.0% |   497.6% |  7.46% |  2.74% |  0.45% |
|  8960 |   15.7% |   17.2% |     0.0% |  7.46% |  2.74% |  0.45% |
|  9000 |   15.2% |   16.7% |   100.0% |  7.46% |  2.74% |  0.45% |
#+TBLFM: @3$2..@3$4=@2-$ipso::@3$5..@3$7=@2-$tfso::$1=remote(obytes,@@#$1)::@4$2..@>$4=100*remote(obytes,@@#$$#)/$1;%.1f%%::@4$5..@>$7=100*$tfso/(@3/$1)/$1;%.2f%%
#+END_CENTER

** Comparing Available Bandwidth

Another way to compare the two solutions is to look at the amount of
available bandwidth each solution provides. The following sections
consider and compare the percentage of available bandwidth. For the
sake of providing a well understood baseline we will also include
normal (unencrypted) Ethernet as well as normal ESP values.

*** Ethernet

In order to calculate the available bandwidth we first calculate the
per packet overhead in bits. The total overhead of Ethernet is 14+4
octets of header and CRC plus and additional 20 octets of framing
(preamble, start, and inter-packet gap) for a total of 48 octets.
Additionally the minimum payload is 46 octets.

# *** IP-TFS Bandwidth
# *** ESP with Padding Bandwidth

#+BEGIN_CENTER
#+BEGIN_NOEXPORT

#+TBLNAME: reqdbytes
| Size |   E+P |   E+P |   E+P |     IPTFS |     IPTFS |     IPTFS | Enet |  ESP |
|  MTU |   590 |  1514 |  9014 |       590 |      1514 |      9014 |  any |  any |
|   OH |    74 |    74 |    74 |        78 |        78 |        78 |   38 |   74 |
|------+-------+-------+-------+-----------+-----------+-----------+------+------|
|   40 |   614 |  1538 |  9038 | 45.820896 | 42.136986 | 40.348214 |   84 |  114 |
|  128 |   614 |  1538 |  9038 | 146.62687 | 134.83836 | 129.11428 |  166 |  202 |
|  256 |   614 |  1538 |  9038 | 293.25373 | 269.67672 | 258.22858 |  294 |  330 |
|  536 |   614 |  1538 |  9038 |       614 | 564.63562 | 540.66608 |  574 |  610 |
|  576 |  1228 |  1538 |  9038 | 659.82092 | 606.77261 | 581.01428 |  614 |  650 |
| 1460 |  1842 |  1538 |  9038 | 1672.4627 |      1538 | 1472.7098 | 1498 | 1534 |
| 1500 |  1842 |  3076 |  9038 | 1718.2836 | 1580.1370 | 1513.0580 | 1538 | 1574 |
| 8960 | 11052 | 10766 |  9038 | 10263.881 | 9438.6849 |      9038 | 8998 | 9034 |
| 9000 | 11052 | 10766 | 18076 | 10309.702 | 9480.8220 | 9078.3483 | 9038 | 9074 |
#+TBLFM: @2$2..@2$7=remote(obytes,@2$$#)+14::@3$2..@3$4=$etho + $ipso::@3$5..@3$7=$etho + $tfso::@4$2..@>$7=remote(reqdpackets,@@#$$#)*(@2+24);p40::@4$8..@>$>=max(84,$1+@I-1);p40
#+END_NOEXPORT

#+CAPTION: L2 Octets Per Packet
| Size | E + P | E + P | E + P | IPTFS | IPTFS | IPTFS | Enet |  ESP |
|  MTU |   590 |  1514 |  9014 |   590 |  1514 |  9014 |  any |  any |
|   OH |    74 |    74 |    74 |    78 |    78 |    78 |   38 |   74 |
|------+-------+-------+-------+-------+-------+-------+------+------|
|   40 |   614 |  1538 |  9038 |    45 |    42 |    40 |   84 |  114 |
|  128 |   614 |  1538 |  9038 |   146 |   134 |   129 |  166 |  202 |
|  256 |   614 |  1538 |  9038 |   293 |   269 |   258 |  294 |  330 |
|  536 |   614 |  1538 |  9038 |   614 |   564 |   540 |  574 |  610 |
|  576 |  1228 |  1538 |  9038 |   659 |   606 |   581 |  614 |  650 |
| 1460 |  1842 |  1538 |  9038 |  1672 |  1538 |  1472 | 1498 | 1534 |
| 1500 |  1842 |  3076 |  9038 |  1718 |  1580 |  1513 | 1538 | 1574 |
| 8960 | 11052 | 10766 |  9038 | 10263 |  9438 |  9038 | 8998 | 9034 |
| 9000 | 11052 | 10766 | 18076 | 10309 |  9480 |  9078 | 9038 | 9074 |
#+TBLFM: $1=remote(reqdbytes,$1)::@1$2..@3$>=remote(reqdbytes,@@#$$#)::@4$2..@>$4=remote(reqdbytes,@@#$$#)::@4$5..@>$7=remote(reqdbytes,@@#$$#);%d

#+BEGIN_NOEXPORT
#+TBLNAME: pps
| Size |     E + P |     E + P |     E + P |     IPTFS |     IPTFS |     IPTFS |      Enet |       ESP |
|  MTU |       590 |      1514 |      9014 |       590 |      1514 |      9014 |       any |       any |
|   OH |        74 |        74 |        74 |        78 |        78 |        78 |        38 |        74 |
|------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------|
|   40 | 2035830.6 | 812743.82 | 138304.93 | 27280130. | 29665150. | 30980306. | 14880952. | 10964912. |
|  128 | 2035830.6 | 812743.82 | 138304.93 | 8525040.5 | 9270359.0 | 9681345.9 | 7530120.5 | 6188118.8 |
|  256 | 2035830.6 | 812743.82 | 138304.93 | 4262520.4 | 4635179.5 | 4840672.6 | 4251700.7 | 3787878.8 |
|  536 | 2035830.6 | 812743.82 | 138304.93 | 2035830.6 | 2213817.1 | 2311963.1 | 2177700.3 | 2049180.3 |
|  576 | 1017915.3 | 812743.82 | 138304.93 | 1894453.4 | 2060079.8 | 2151410.1 | 2035830.6 | 1923076.9 |
| 1460 | 678610.21 | 812743.82 | 138304.93 | 747400.82 | 812743.82 | 848775.50 | 834445.93 | 814863.10 |
| 1500 | 678610.21 | 406371.91 | 138304.93 | 727470.13 | 791070.65 | 826141.50 | 812743.82 | 794155.02 |
| 8960 | 113101.70 | 116106.26 | 138304.93 | 121786.29 | 132433.70 | 138304.93 | 138919.76 | 138366.17 |
| 9000 | 113101.70 | 116106.26 | 69152.467 | 121245.02 | 131845.11 | 137690.24 | 138304.93 | 137756.23 |
#+TBLFM: @1$1..@>$1=remote(reqdbytes,@@#$$#)::@1$2..@3$>=remote(reqdbytes,@@#$$#)::@4$2..@>$>=(1e10/8)/remote(reqdbytes,@@#$$#)
#+END_NOEXPORT

# $8 = (1e10/8)/(max(46,$1)+38)
# $9 = (1e10/8)/($1+74)

#+CAPTION: Packets Per Second on 10G Ethernet
| Size | E + P | E + P | E + P | IPTFS | IPTFS | IPTFS | Enet  | ESP   |
|  MTU | 590   | 1514  | 9014  | 590   | 1514  | 9014  | any   | any   |
|   OH | 74    | 74    | 74    | 78    | 78    | 78    | 38    | 74    |
|------+-------+-------+-------+-------+-------+-------+-------+-------|
|   40 | 2.0M  | 0.8M  | 0.1M  | 27.3M | 29.7M | 31.0M | 14.9M | 11.0M |
|  128 | 2.0M  | 0.8M  | 0.1M  | 8.5M  | 9.3M  | 9.7M  | 7.5M  | 6.2M  |
|  256 | 2.0M  | 0.8M  | 0.1M  | 4.3M  | 4.6M  | 4.8M  | 4.3M  | 3.8M  |
|  536 | 2.0M  | 0.8M  | 0.1M  | 2.0M  | 2.2M  | 2.3M  | 2.2M  | 2.0M  |
|  576 | 1.0M  | 0.8M  | 0.1M  | 1.9M  | 2.1M  | 2.2M  | 2.0M  | 1.9M  |
| 1460 | 678K  | 812K  | 138K  | 747K  | 812K  | 848K  | 834K  | 814K  |
| 1500 | 678K  | 406K  | 138K  | 727K  | 791K  | 826K  | 812K  | 794K  |
| 8960 | 113K  | 116K  | 138K  | 121K  | 132K  | 138K  | 138K  | 138K  |
| 9000 | 113K  | 116K  | 69K   | 121K  | 131K  | 137K  | 138K  | 137K  |
#+TBLFM: $1=remote(pps,$1)::@1$2..@3$>=remote(pps,@@#$$#)::@4$2..@8$>=remote(pps,@@#$$#)/1000000;%.1fM::@9$2..@>$>=remote(pps,@@#$$#)/1000;%dK

#+CAPTION: Percentage of Bandwidth on 10G Ethernet
#+TBLNAME: bwpercent
| Size |  E + P |  E + P |  E + P |  IPTFS |  IPTFS |  IPTFS |   Enet |    ESP |
|      |    590 |   1514 |   9014 |    590 |   1514 |   9014 |    any |    any |
|      |     74 |     74 |     74 |     78 |     78 |     78 |     38 |     74 |
|------+--------+--------+--------+--------+--------+--------+--------+--------|
|   40 |  6.51% |  2.60% |  0.44% | 87.30% | 94.93% | 99.14% | 47.62% | 35.09% |
|  128 | 20.85% |  8.32% |  1.42% | 87.30% | 94.93% | 99.14% | 77.11% | 63.37% |
|  256 | 41.69% | 16.64% |  2.83% | 87.30% | 94.93% | 99.14% | 87.07% | 77.58% |
|  536 | 87.30% | 34.85% |  5.93% | 87.30% | 94.93% | 99.14% | 93.38% | 87.87% |
|  576 | 46.91% | 37.45% |  6.37% | 87.30% | 94.93% | 99.14% | 93.81% | 88.62% |
| 1460 | 79.26% | 94.93% | 16.15% | 87.30% | 94.93% | 99.14% | 97.46% | 95.18% |
| 1500 | 81.43% | 48.76% | 16.60% | 87.30% | 94.93% | 99.14% | 97.53% | 95.30% |
| 8960 | 81.07% | 83.22% | 99.14% | 87.30% | 94.93% | 99.14% | 99.58% | 99.18% |
| 9000 | 81.43% | 83.60% | 49.79% | 87.30% | 94.93% | 99.14% | 99.58% | 99.18% |
#+TBLFM: $1=remote(pps,$1)::@1$2..@3$>=remote(pps,@@#$$#)::@4$2..@>$9=(100*$1*remote(pps,@@#$$#))/(1e10/8);%.2f%%
#+END_CENTER

A sometimes unexpected result of using IP-TFS (or any packet
aggregating tunnel) is that, for small to medium sized packets, the
available bandwidth is actually greater than native Ethernet. This is
due to the reduction in Ethernet framing overhead. This increased
bandwidth is paid for with an increase in latency. This latency is
the time to send the unrelated octets in the outer tunnel frame. The
following table illustrates the latency for some common values on a
10G Ethernet link. The table also includes latency introduced by
padding if using ESP with padding.

#+BEGIN_CENTER
#+CAPTION: Added Latency
|      | ESP+Pad | ESP+Pad | IP-TFS  | IP-TFS  |
|      | 1500    | 9000    | 1500    | 9000    |
|      |         |         |         |         |
|------+---------+---------+---------+---------|
|   40 | 1.14 us | 7.14 us | 1.17 us | 7.17 us |
|  128 | 1.07 us | 7.07 us | 1.10 us | 7.10 us |
|  256 | 0.97 us | 6.97 us | 1.00 us | 7.00 us |
|  536 | 0.74 us | 6.74 us | 0.77 us | 6.77 us |
|  576 | 0.71 us | 6.71 us | 0.74 us | 6.74 us |
| 1460 | 0.00 us | 6.00 us | 0.04 us | 6.04 us |
| 1500 | 1.20 us | 5.97 us | 0.00 us | 6.00 us |
#+TBLFM: $2=(remote(obytes,@@#$3)*8)/10000;%.2f us::$3=(remote(obytes,@@#$4)*8)/10000;%.2f us::@4$4..@>$>=(((@2+4-$1)*8)/10000);%.2f us
#+END_CENTER

Notice that the latency values are very similar between the two
solutions; however, whereas IP-TFS provides for constant high
bandwidth, in some cases even exceeding native Ethernet, ESP with
padding often greatly reduces available bandwidth.

* Deriving TFRC Parameters

The parameters required to implement the algorithm defined in
[[RFC5348]] are: ~s~, ~R~, ~p~, ~t_RTO~ and ~b~. These values are used in
the following formula to calculate the sending rate.

#+begin_example
                                s
   X_Bps = ----------------------------------------------------------
           R*sqrt(2*b*p/3) + (t_RTO * (3*sqrt(3*b*p/8)*p*(1+32*p^2)))
#+end_example

Per [[RFC5348]] ~b~ can be set to ~1~ and t_RTO to ~4*R~ and the formula
reduces to:

#+begin_example
                                s
   X_Bps = -----------------------------------------------
           R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*p^2))
#+end_example

Per [[RFC5348]] also indicates that ~X_Bps~ can be specified as ~X_pps *
s~ which then yields

#+begin_example
                                1
   X_Pps = -----------------------------------------------
           R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*p^2))
#+end_example

The following sections describe how to derive the remaining values
from the information provided by IP-TFS.

** ~R~: Round-trip Time (4.3)
   This value is in seconds.

#+begin_example
   1)  Calculate a new round-trip sample:

      R_sample = (t_now - t_recvdata) - t_delay.

   As described in Section 3.2.2, t_delay gives the elapsed time at the
   receiver.

   2)  Update the round-trip time estimate:

      If no feedback has been received before {
          R = R_sample;
      } Else {
          R = q*R + (1-q)*R_sample;
      }
#+end_example


** ~p~: Loss Event Rate (5)
   Section 5 of [[RFC5348]] defines the calculation of the Loss Event
   Rate ~p~.


** Example using minimum round-trip time

The minimum round-trip time (~R~) for a link is 2 times the
transmission time for a packet plus some possible small but non-zero
processing time. Let's consider 1500B (12000 bit) packets. If we can
transmit ~X~ bits per second, then we can transmit ~X/12000~ pps, and
so ~1/(X/12000)~ or ~12000/X~ is the transmit time of one packet and
the min ~R~ is twice that (~24000/X~).

| Link Speed |     pps |      R | pprtt |
|------------+---------+--------+-------|
| 10M        |  833.33 |  .0024 |       |
| 100M       | 8333.33 | .00024 |       |
| 1GE        |         | 2.4e-5 |       |
| 10GE       |         | 2.4e-6 |       |
| 100GE      |         | 2.4e-7 |       |


Now let's consider a loss rate of 1 packet every second on a 10M link.

p = 1/832

#+begin_src python :results output :var linkspeed=100000 :var psize=1500 :var lossint=4294967295
    from math import sqrt
    linkspeed *= 1000000
    psize *= 8.
    print("psize:", psize)
    prate = linkspeed / psize
    print("prate:", prate)
    # R = 10 * 2. * psize / linkspeed
    R = .003
    print("R:", R)
    p = 1. / lossint
    print("p:", p)
    denom = R * (sqrt(2*p/3) + 12*sqrt(3*p/8)*p*(1+32*(p**2)))
    print("denom:", denom)
    pps = 1. / denom
    print(pps)
    # return pps
#+end_src

#+RESULTS:
: psize: 12000.0
: prate: 8333333.333333333
: R: 0.003
: p: 2.3283064370807974e-10
: denom: 3.737624737855809e-08
: 26754959.90466067


                                1
   X_Pps = -----------------------------------------------
           R * (sqrt(2*.5/3) + 12*sqrt(3*.5/8)*.5*(1+32*.5^2))

                                1
   X_Pps = -----------------------------------------------
           R * (sqrt(1/3) + 12*sqrt(.1875) * .5 * (9) )

                           1
   X_Pps = ----------------------------------
            R * (sqrt(1/3) + 54*sqrt(.1875))

                                1
   X_Pps = -------------------------------------
             R * (0.577350269189+23.3826859022)

            23.9600361714
                                1
   X_Pps = -----------------------------------------------
           R * (sqrt(2*2/3) + 12*sqrt(3*2/8)*2*(1+32*2^2))

2682.369351.15470053838065


R * (1.15470053838 + 12*0.866025403784*2*(1+128))
(1.15470053838 + 12*0.866025403784*2*(1+128))

2682.36935065 * .0024
6.43768644156

                  1
   X_Pps = ----------------
           R * (sqrt(2*0/3)

* Acknowledgements
We would like to thank Don Fedyk for help in reviewing this work.

* Contributors
The following people made significant contributions to this document.

#+begin_example
   Lou Berger
   LabN Consulting, L.L.C.

   Email: lberger@labn.net
#+end_example
